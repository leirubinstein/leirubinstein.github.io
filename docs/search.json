[
  {
    "objectID": "nature-photography.html",
    "href": "nature-photography.html",
    "title": "Nature Photography",
    "section": "",
    "text": "Kelp forests at Santa Cruz Island, Channel Islands National Park\n\n\n\n\n\nDolphin breaching water in the Santa Barbara Channel, CA\n\n\n\n\n\nDolphins in the Santa Barbara Channel, CA\n\n\n\n\n\nSchool of sardines in the Santa Barbara Channel, CA\n\n\n\n\n\nMount San Jacinto, Palm Springs, CA\n\n\n\n\n\nWindmills outside of Palm Springs, CA\n\n\n\n\n\nSunset from More Mesa, Santa Barbara, CA\n\n\n\n\n\nUCSB Lagoon, Santa Barbara, CA\n\n\n\n\n\nDead Sea sunrise from Masada, Israel"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Biography\nI earned my Bachelor of Arts in Political Science and Environmental Studies from the University of California, Santa Barbara in 2021. Inspired by Santa Barbara’s legacy of environmental activism, I have dedicated myself to running local and federal campaigns with social justice and conservation-driven values for the past seven years. Following my undergraduate degree, I worked at an environmental law firm, specializing in litigation and regulatory disputes relating to remediation of Superfund sites. My professional experience includes roles in political organizing, legislation, and environmental law, where I honed skills in public communication, community engagement, and environmental policy analysis.\nCurrently pursuing a Master of Environmental Data Science at the Bren School, I aspire to work in environmental economics research or government. I aim to leverage remote sensing and machine learning techniques to develop solutions for resource management and climate change mitigation, promoting sustainable practices and enhancing climate resilience locally and globally.\nIn my free time, I enjoy biking, gaming, and exploring nature and the night sky through my camera lens."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Leilanie Rubinstein",
    "section": "",
    "text": "I earned my Bachelor of Arts in Political Science and Environmental Studies from the University of California, Santa Barbara in 2021. Inspired by Santa Barbara’s legacy of environmental activism, I have dedicated myself to running local and federal campaigns with social justice and conservation-driven values for the past seven years. Following my undergraduate degree, I worked at an environmental law firm, specializing in litigation and regulatory disputes relating to remediation of Superfund sites, the Clean Air Act, and the Clean Water Act. My professional experience includes roles in political organizing, legislation, and environmental law, where I honed skills in public communication, community engagement, and environmental policy analysis.\nCurrently pursuing a Master of Environmental Data Science at the Bren School, I am excited about working with spatial data and remote sensing technologies. Using the\nI aspire to work in environmental economics research or government. I aim to leverage remote sensing and machine learning techniques to develop solutions for resource management and climate change mitigation, while bridging the science-policy divide.\nAt Bren, Cullen has been excited about working with spatial data and remote sensing technologies. He uses these skills for his capstone project where his team is developing a workflow that uses satellite imagery and machine learning to make crop yield predictions in sub-Saharan Africa.\nIn my free time, I enjoy biking, gaming, and exploring nature and the night sky through my camera lens. Check out some of my photography here."
  },
  {
    "objectID": "posts/2025-03-14-political-data-viz/HW4-blogpost.html",
    "href": "posts/2025-03-14-political-data-viz/HW4-blogpost.html",
    "title": "Final Blog Post",
    "section": "",
    "text": "Final Blog Post\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n    \n    Author\n    \n             Leilanie Rubinstein \n          \n  \n    \n    \n    Published\n    \n      March 15, 2025\n    \n  \n  \n    \n  \n  \n\n\n\n\n\nSince childhood, I’ve been interested in politics– a fault I attribute to my dad. We were your typical liberal Prius-driving NPR listeners and CNN-blaring-in-the-background household. Upon moving to Santa Barbara in 2017 for my undergraduate degree, I’ve volunteered or worked in every election, traveling up and down the county to knock on doors for local candidates with pro-environment and pro-housing values.\nMost people assume Santa Barbara is a beautiful oceanside haven for liberal, white, and wealthy– and to some extent, it is. But I’d like to explore some specific trends in voter demographics at a county level:\n\nHow are Democratic and Republican voters spatially distributed throughout the county?\nIs there a partisan difference between the ages of voters in Santa Barbara and Goleta?\nHow do voter registrations change over time?\n\nMost visualizations of voter data happen at the county level, rather than within counties. Furthermore, election data from the 2024 general election has not been fully certified yet for most counties in California. I aim to provide a quick overview of the political composition of our county for people interested in local politics.\n\n\n\nThe Santa Barbara County voter registration data used for this project was requested from SB County Elections, and is dated for May 9, 2025. It contains voter registration information (voter name, address, contact information, voting precinct, and political party affiliation).\nFor census data, I use the tidycensus package, with 2023 geometries and population surveys.\n\n\n\n\nHow old are Democrats vs. Republicans? For this visualization, I chose stacked bar charts to visualize the age breakdowns within each party, narrowing the focus to the cities of Santa Barbara and Goleta. On average, Democrats are slightly younger than Republicans in both cities. However, older voters represent the greatest share of voters in both political parties. I would have liked to make the bars different colors for each political party, but was having difficulty separating the bars.\nWhen do people register to vote? Voters generally register to vote closer to elections, and we can see that there is a noticeable spike in the line graph of number of registrations each general election year (labeled on the x-axis).\nHow are voters distributed across the county? I wanted to plot the difference in percentage of Democrats compared to Republicans across the county. I chose a chloropleth map to visualize this, because it is a good way to display spatial relationships. In Santa Barbara, urban centers in South County tend to lean heavily Democratic, while more rural areas are Republican. One challenge with displaying partisanship on a chloropleth map, however, is the visual overrepresentation of sparsely populated but large geographic areas. It appears as though a large portion of the county is red, when in reality very few people live in those areas, and the county as a whole leans solidly Democratic. This is why I’ve included a supplementary waffle plot displaying the proportion of voters by party.\n\n\n\n\n\n# -------------- Setup --------------\n# Load packages\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\nlibrary(tidycensus)\nlibrary(ggmap)\nlibrary(sf)\nlibrary(tigris)\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(tidygeocoder)\nlibrary(tmap)\nlibrary(tmaptools)\nlibrary(waffle)\nlibrary(patchwork)\n\n# Set census API key\ncensus_api_key(Sys.getenv(\"CENSUS_API_KEY\"))\n\n\n# -------------- Theme & Colors --------------\n# Customize font and theme\nfont_add_google(\"EB Garamond\", \"EBGaramond\")\nshowtext_auto()\ntheme_set(theme_bw())\n\n# Custom colors\nparty_colors &lt;- c(\n    \"DEM\" = \"#0f6ba8\",\n    \"REP\" = \"#c83236\",\n    \"NPP\" = \"#694e7a\",\n    \"Other\" = \"gray50\",\n    \"Democrat\" = \"#026CA1\",\n    \"Republican\" = \"#CA2C2C\",\n    \"No Party Preference\" = \"#CECECE\",\n    \"American Independent\" = \"#989898\",\n    \"Libertarian\" = \"#FFD500\",\n    \"Unknown\" = \"gray30\",\n    \"Peace and Freedom\" = \"#7459A7\",\n    \"Green\" = \"#54B643\"\n)\n\n\n# -------------- Data Import --------------\n# Read in voter data\nfull_file &lt;- read_delim(\n    here::here(\"data/Countywide_Voter Registration 030325.TXT\"),\n    delim = \"\\t\"\n) %&gt;%\n    clean_names()\n\n# full_file &lt;- read_delim(\n#     here::here(\"EDS-240-DATA-VIZ/rubinstein-eds240-HW4/data/Countywide_Voter Registration 030325.TXT\"),\n#     delim = \"\\t\"\n# ) %&gt;%\n#     clean_names()\n\n\n\n\n# -------------- Visualization 1: Age Composition by Party --------------\n# Calculate age distribution by city and party\nvoter_ages &lt;- full_file %&gt;%\n    mutate(\n        age = interval(dob, today()) %/% years(1),\n        age_group = cut(\n            age,\n            breaks = c(18, 25, 35, 50, 65, Inf),\n            labels = c(\"18-25\", \"26-35\", \"36-50\", \"51-65\", \"65+\"),\n            right = FALSE\n        ),\n        party_code = factor(party_code, levels = c(\"DEM\", \"REP\"))\n    ) %&gt;%\n    filter(!is.na(party_code)) %&gt;%\n    filter(city %in% c(\"SANTA BARBARA\", \"GOLETA\")) %&gt;%\n    group_by(city, party_code) %&gt;%\n    mutate(city_party_total = n()) %&gt;%\n    group_by(city, party_code, age_group) %&gt;%\n    summarize(\n        count = n(),\n        pct = count / first(city_party_total),\n        .groups = \"drop\"\n    )\n\n# Fix city order\nvoter_ages$city &lt;- factor(\n    voter_ages$city,\n    levels = c(\"SANTA BARBARA\", \"GOLETA\")\n)\n\n# Create age distribution plot with party comparison as proportions and labels\nggplot(\n    voter_ages,\n    aes(x = party_code, y = pct, fill = age_group)\n) +\n    geom_col() +\n    # Add text labels inside the bars\n    geom_text(\n        aes(label = scales::percent(pct, accuracy = 1)),\n        position = position_stack(vjust = 0.5),\n        color = \"white\",\n        fontface = \"bold\",\n        size = 3\n    ) +\n    facet_grid(city ~ .) +\n    scale_fill_brewer(palette = \"Purples\", direction = 1) +\n    scale_y_continuous(\n        labels = scales::percent,\n        breaks = seq(0, 1, 0.2)\n    ) +\n    labs(\n        title = \"Age Distribution of Voters in Santa Barbara and Goleta by Party\",\n        subtitle = \"Comparing proportions of Democratic and Republican voters by age group\\n\",\n        x = NULL,\n        y = \"Proportion of Registered Voters\\n\",\n        fill = \"Age Group\",\n        caption = \"\\nSource: Santa Barbara Voter File (2025)\"\n    ) +\n    theme(\n        panel.grid.major.y = element_blank(),\n        text = element_text(family = \"EBGaramond\"),\n        axis.text = element_text(family = \"EBGaramond\"),\n        plot.title = element_text(\n            size = 12,\n            face = \"bold\",\n            family = \"EBGaramond\"\n        ),\n        strip.text = element_text(size = 11, face = \"bold\"),\n        plot.subtitle = element_text(family = \"EBGaramond\"),\n        plot.caption = element_text(family = \"EBGaramond\"),\n        legend.text = element_text(family = \"EBGaramond\")\n    )\n\n\n\n\n\n\n\n\n# -------------- Visualization 2: Registration Trends --------------\n# Analyze registrations over time\nyearly_registration &lt;- full_file %&gt;%\n    mutate(year = format(registration_date, \"%Y\")) %&gt;%\n    filter(year &gt;= \"2000\") %&gt;%\n    filter(year &lt;= \"2024\") %&gt;%\n    count(year)\n\n# Create time series plot\nggplot(yearly_registration, aes(x = year, y = n)) +\n    geom_line(group = 1, color = \"purple\") +\n    geom_point(color = \"purple\") +\n    labs(\n        title = \"Voter Registrations in Santa Barbara County\",\n        subtitle = \"Number of new registrations from 2000 - 2024, showing spikes in new registrations during general election years\",\n        x = \"Year\",\n        y = \"Number of New Registrations\"\n    ) +\n    scale_x_discrete(\n        breaks = seq(\n            from = min(yearly_registration$year),\n            to = max(yearly_registration$year),\n            by = 4\n        )\n    ) +\n    theme(\n        panel.grid.major.y = element_blank(),\n        text = element_text(size = 24, family = \"EBGaramond\"),\n        axis.text = element_text(family = \"EBGaramond\"),\n        plot.title = element_text(face = \"bold\", family = \"EBGaramond\"),\n        plot.subtitle = element_text(family = \"EBGaramond\"),\n        plot.caption = element_text(family = \"EBGaramond\"),\n        legend.text = element_text(family = \"EBGaramond\")\n    )\n\n\n\n\n\n\n\n\n# -------------- Geocoding & Spatial Analysis --------------\n# Prepare addresses for geocoding\naddress_full &lt;- full_file %&gt;%\n    mutate(street_address_test = paste(address_number, street_name, sep = \" \"))\n\n# Geocoding function\ngeocode_addresses &lt;- function() {\n    census_list &lt;- list()\n    for (j in 1:25) {\n        start_index &lt;- ((j - 1) * 10000) + 1\n        end_index &lt;- j * 10000\n\n        census_list[[j]] &lt;- address_full[start_index:end_index, ] %&gt;%\n            tidygeocoder::geocode(\n                street = street_address_test,\n                city = city,\n                state = state,\n                method = \"census\"\n            )\n    }\n\n    final_census_df &lt;- bind_rows(census_list) %&gt;%\n        filter(party_code %in% c(\"DEM\", \"REP\", \"NPP\")) %&gt;%\n        drop_na(lat)\n\n    # Save for future use\n    saveRDS(final_census_df, \"geocoded_addresses.rds\")\n\n    return(final_census_df)\n}\n\nfinal_census_df &lt;- geocode_addresses()\n# final_census_df &lt;- readRDS(\"geocoded_addresses.rds\")\n\n\n# -------------- Spatial Visualization --------------\n# Convert to geocoded addresses to sf object\nfinal_census_sf &lt;- st_as_sf(\n    final_census_df,\n    coords = c(\"long\", \"lat\"),\n    crs = 4326\n)\n\n# Get total population by census tract for Santa Barbara County\nsb_pop_2023 &lt;- get_acs(\n    geography = \"tract\",\n    variables = \"B01003_001\", # Total population variable\n    state = \"CA\",\n    county = \"Santa Barbara\",\n    year = 2023,\n    geometry = TRUE\n) %&gt;%\n    st_transform(crs = 4326)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=======                                                               |  11%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |==============                                                        |  21%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  59%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |======================================================================| 100%\n\n# Join voters to tracts and calculate party percentages\nvoters_with_tract &lt;- st_join(final_census_sf, sb_pop_2023)\n\nparty_by_tract &lt;- voters_with_tract %&gt;%\n    st_drop_geometry() %&gt;%\n    group_by(GEOID) %&gt;%\n    mutate(tract_total = n()) %&gt;%\n    group_by(GEOID, party_code, tract_total) %&gt;%\n    summarize(count = n()) %&gt;%\n    mutate(percentage = count / tract_total * 100) %&gt;%\n    ungroup()\n\n# Create a dataset with relative Dem-Rep percentages (excluding other parties)\ntwo_party_comparison &lt;- party_by_tract %&gt;%\n  filter(party_code %in% c(\"DEM\", \"REP\")) %&gt;%\n  group_by(GEOID) %&gt;%\n  mutate(two_party_total = sum(count)) %&gt;%\n  # Recalculate percentages based only on Dem + Rep voters\n  mutate(two_party_pct = count / two_party_total * 100) %&gt;%\n  select(GEOID, party_code, two_party_pct) %&gt;%\n  pivot_wider(\n    names_from = party_code,\n    values_from = two_party_pct\n  ) %&gt;%\n  mutate(diff = DEM - REP)\n\n# Join the difference data to the geometry\ntract_diff_map &lt;- sb_pop_2023 %&gt;%\n  select(GEOID, geometry) %&gt;%\n  left_join(two_party_comparison, by = \"GEOID\") %&gt;%\n  filter(!is.na(diff))\n\n# Create the divergent map\nggplot() +\n  geom_sf(data = tract_diff_map, aes(fill = diff)) +\n  scale_fill_gradient2(\n    low = party_colors[\"REP\"],\n    mid = \"#FFFFFF\",               \n    high = party_colors[\"DEM\"],\n    midpoint = 0,\n    name = \"Dem-Rep Difference (%)\"\n  ) +\n  labs(\n    title = \"Democratic vs. Republican Voter Distribution by Census Tract\",\n    subtitle = \"Percentage difference between parties (excluding other affiliations)\"\n  ) +\n  theme_void()\n\n\n\n\n\n# -------------- Waffle Chart --------------\n# Create waffle chart of party distribution\nwaffle_counts &lt;- full_file %&gt;%\n    mutate(\n        party_code = if_else(\n            party_code %in% c(\"DEM\", \"REP\", \"NPP\"),\n            party_code,\n            \"Other\"\n        )\n    ) %&gt;%\n    count(party_code) %&gt;%\n    mutate(\n        party_code = factor(\n            party_code,\n            levels = c(\"DEM\", \"REP\", \"NPP\", \"Other\")\n        )\n    )\n\n# Limit total squares for better display\nmax_squares &lt;- 200\nif (sum(waffle_counts$n) &gt; max_squares) {\n    waffle_counts &lt;- waffle_counts %&gt;%\n        mutate(n = round(n * max_squares / sum(n)))\n}\n\n# Create waffle chart\nggplot(waffle_counts, aes(fill = party_code, values = n)) +\n    geom_waffle(color = \"white\", size = 0.5, n_rows = 10) +\n    scale_fill_manual(values = party_colors) +\n    coord_fixed() +\n    theme_void() +\n    labs(\n        title = \"Party Distribution in Santa Barbara County\",\n        fill = \"Party\"\n    )"
  },
  {
    "objectID": "posts/2025-03-14-political-data-viz/HW4-blogpost.html#why-voter-data",
    "href": "posts/2025-03-14-political-data-viz/HW4-blogpost.html#why-voter-data",
    "title": "Final Blog Post",
    "section": "",
    "text": "Since childhood, I’ve been interested in politics– a fault I attribute to my dad. We were your typical liberal Prius-driving NPR listeners and CNN-blaring-in-the-background household. Upon moving to Santa Barbara in 2017 for my undergraduate degree, I’ve volunteered or worked in every election, traveling up and down the county to knock on doors for local candidates with pro-environment and pro-housing values.\nMost people assume Santa Barbara is a beautiful oceanside haven for liberal, white, and wealthy– and to some extent, it is. But I’d like to explore some specific trends in voter demographics at a county level:\n\nHow are Democratic and Republican voters spatially distributed throughout the county?\nIs there a partisan difference between the ages of voters in Santa Barbara and Goleta?\nHow do voter registrations change over time?\n\nMost visualizations of voter data happen at the county level, rather than within counties. Furthermore, election data from the 2024 general election has not been fully certified yet for most counties in California. I aim to provide a quick overview of the political composition of our county for people interested in local politics."
  },
  {
    "objectID": "posts/2025-03-14-political-data-viz/HW4-blogpost.html#about-the-data",
    "href": "posts/2025-03-14-political-data-viz/HW4-blogpost.html#about-the-data",
    "title": "Final Blog Post",
    "section": "",
    "text": "The Santa Barbara County voter registration data used for this project was requested from SB County Elections, and is dated for May 9, 2025. It contains voter registration information (voter name, address, contact information, voting precinct, and political party affiliation).\nFor census data, I use the tidycensus package, with 2023 geometries and population surveys."
  },
  {
    "objectID": "posts/2025-03-14-political-data-viz/HW4-blogpost.html#visualizations",
    "href": "posts/2025-03-14-political-data-viz/HW4-blogpost.html#visualizations",
    "title": "Final Blog Post",
    "section": "",
    "text": "How old are Democrats vs. Republicans? For this visualization, I chose stacked bar charts to visualize the age breakdowns within each party, narrowing the focus to the cities of Santa Barbara and Goleta. On average, Democrats are slightly younger than Republicans in both cities. However, older voters represent the greatest share of voters in both political parties. I would have liked to make the bars different colors for each political party, but was having difficulty separating the bars.\nWhen do people register to vote? Voters generally register to vote closer to elections, and we can see that there is a noticeable spike in the line graph of number of registrations each general election year (labeled on the x-axis).\nHow are voters distributed across the county? I wanted to plot the difference in percentage of Democrats compared to Republicans across the county. I chose a chloropleth map to visualize this, because it is a good way to display spatial relationships. In Santa Barbara, urban centers in South County tend to lean heavily Democratic, while more rural areas are Republican. One challenge with displaying partisanship on a chloropleth map, however, is the visual overrepresentation of sparsely populated but large geographic areas. It appears as though a large portion of the county is red, when in reality very few people live in those areas, and the county as a whole leans solidly Democratic. This is why I’ve included a supplementary waffle plot displaying the proportion of voters by party."
  },
  {
    "objectID": "posts/2025-03-14-political-data-viz/HW4-blogpost.html#code-for-visualizations",
    "href": "posts/2025-03-14-political-data-viz/HW4-blogpost.html#code-for-visualizations",
    "title": "Final Blog Post",
    "section": "",
    "text": "# -------------- Setup --------------\n# Load packages\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\nlibrary(tidycensus)\nlibrary(ggmap)\nlibrary(sf)\nlibrary(tigris)\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(tidygeocoder)\nlibrary(tmap)\nlibrary(tmaptools)\nlibrary(waffle)\nlibrary(patchwork)\n\n# Set census API key\ncensus_api_key(Sys.getenv(\"CENSUS_API_KEY\"))\n\n\n# -------------- Theme & Colors --------------\n# Customize font and theme\nfont_add_google(\"EB Garamond\", \"EBGaramond\")\nshowtext_auto()\ntheme_set(theme_bw())\n\n# Custom colors\nparty_colors &lt;- c(\n    \"DEM\" = \"#0f6ba8\",\n    \"REP\" = \"#c83236\",\n    \"NPP\" = \"#694e7a\",\n    \"Other\" = \"gray50\",\n    \"Democrat\" = \"#026CA1\",\n    \"Republican\" = \"#CA2C2C\",\n    \"No Party Preference\" = \"#CECECE\",\n    \"American Independent\" = \"#989898\",\n    \"Libertarian\" = \"#FFD500\",\n    \"Unknown\" = \"gray30\",\n    \"Peace and Freedom\" = \"#7459A7\",\n    \"Green\" = \"#54B643\"\n)\n\n\n# -------------- Data Import --------------\n# Read in voter data\nfull_file &lt;- read_delim(\n    here::here(\"data/Countywide_Voter Registration 030325.TXT\"),\n    delim = \"\\t\"\n) %&gt;%\n    clean_names()\n\n# full_file &lt;- read_delim(\n#     here::here(\"EDS-240-DATA-VIZ/rubinstein-eds240-HW4/data/Countywide_Voter Registration 030325.TXT\"),\n#     delim = \"\\t\"\n# ) %&gt;%\n#     clean_names()\n\n\n\n\n# -------------- Visualization 1: Age Composition by Party --------------\n# Calculate age distribution by city and party\nvoter_ages &lt;- full_file %&gt;%\n    mutate(\n        age = interval(dob, today()) %/% years(1),\n        age_group = cut(\n            age,\n            breaks = c(18, 25, 35, 50, 65, Inf),\n            labels = c(\"18-25\", \"26-35\", \"36-50\", \"51-65\", \"65+\"),\n            right = FALSE\n        ),\n        party_code = factor(party_code, levels = c(\"DEM\", \"REP\"))\n    ) %&gt;%\n    filter(!is.na(party_code)) %&gt;%\n    filter(city %in% c(\"SANTA BARBARA\", \"GOLETA\")) %&gt;%\n    group_by(city, party_code) %&gt;%\n    mutate(city_party_total = n()) %&gt;%\n    group_by(city, party_code, age_group) %&gt;%\n    summarize(\n        count = n(),\n        pct = count / first(city_party_total),\n        .groups = \"drop\"\n    )\n\n# Fix city order\nvoter_ages$city &lt;- factor(\n    voter_ages$city,\n    levels = c(\"SANTA BARBARA\", \"GOLETA\")\n)\n\n# Create age distribution plot with party comparison as proportions and labels\nggplot(\n    voter_ages,\n    aes(x = party_code, y = pct, fill = age_group)\n) +\n    geom_col() +\n    # Add text labels inside the bars\n    geom_text(\n        aes(label = scales::percent(pct, accuracy = 1)),\n        position = position_stack(vjust = 0.5),\n        color = \"white\",\n        fontface = \"bold\",\n        size = 3\n    ) +\n    facet_grid(city ~ .) +\n    scale_fill_brewer(palette = \"Purples\", direction = 1) +\n    scale_y_continuous(\n        labels = scales::percent,\n        breaks = seq(0, 1, 0.2)\n    ) +\n    labs(\n        title = \"Age Distribution of Voters in Santa Barbara and Goleta by Party\",\n        subtitle = \"Comparing proportions of Democratic and Republican voters by age group\\n\",\n        x = NULL,\n        y = \"Proportion of Registered Voters\\n\",\n        fill = \"Age Group\",\n        caption = \"\\nSource: Santa Barbara Voter File (2025)\"\n    ) +\n    theme(\n        panel.grid.major.y = element_blank(),\n        text = element_text(family = \"EBGaramond\"),\n        axis.text = element_text(family = \"EBGaramond\"),\n        plot.title = element_text(\n            size = 12,\n            face = \"bold\",\n            family = \"EBGaramond\"\n        ),\n        strip.text = element_text(size = 11, face = \"bold\"),\n        plot.subtitle = element_text(family = \"EBGaramond\"),\n        plot.caption = element_text(family = \"EBGaramond\"),\n        legend.text = element_text(family = \"EBGaramond\")\n    )\n\n\n\n\n\n\n\n\n# -------------- Visualization 2: Registration Trends --------------\n# Analyze registrations over time\nyearly_registration &lt;- full_file %&gt;%\n    mutate(year = format(registration_date, \"%Y\")) %&gt;%\n    filter(year &gt;= \"2000\") %&gt;%\n    filter(year &lt;= \"2024\") %&gt;%\n    count(year)\n\n# Create time series plot\nggplot(yearly_registration, aes(x = year, y = n)) +\n    geom_line(group = 1, color = \"purple\") +\n    geom_point(color = \"purple\") +\n    labs(\n        title = \"Voter Registrations in Santa Barbara County\",\n        subtitle = \"Number of new registrations from 2000 - 2024, showing spikes in new registrations during general election years\",\n        x = \"Year\",\n        y = \"Number of New Registrations\"\n    ) +\n    scale_x_discrete(\n        breaks = seq(\n            from = min(yearly_registration$year),\n            to = max(yearly_registration$year),\n            by = 4\n        )\n    ) +\n    theme(\n        panel.grid.major.y = element_blank(),\n        text = element_text(size = 24, family = \"EBGaramond\"),\n        axis.text = element_text(family = \"EBGaramond\"),\n        plot.title = element_text(face = \"bold\", family = \"EBGaramond\"),\n        plot.subtitle = element_text(family = \"EBGaramond\"),\n        plot.caption = element_text(family = \"EBGaramond\"),\n        legend.text = element_text(family = \"EBGaramond\")\n    )\n\n\n\n\n\n\n\n\n# -------------- Geocoding & Spatial Analysis --------------\n# Prepare addresses for geocoding\naddress_full &lt;- full_file %&gt;%\n    mutate(street_address_test = paste(address_number, street_name, sep = \" \"))\n\n# Geocoding function\ngeocode_addresses &lt;- function() {\n    census_list &lt;- list()\n    for (j in 1:25) {\n        start_index &lt;- ((j - 1) * 10000) + 1\n        end_index &lt;- j * 10000\n\n        census_list[[j]] &lt;- address_full[start_index:end_index, ] %&gt;%\n            tidygeocoder::geocode(\n                street = street_address_test,\n                city = city,\n                state = state,\n                method = \"census\"\n            )\n    }\n\n    final_census_df &lt;- bind_rows(census_list) %&gt;%\n        filter(party_code %in% c(\"DEM\", \"REP\", \"NPP\")) %&gt;%\n        drop_na(lat)\n\n    # Save for future use\n    saveRDS(final_census_df, \"geocoded_addresses.rds\")\n\n    return(final_census_df)\n}\n\nfinal_census_df &lt;- geocode_addresses()\n# final_census_df &lt;- readRDS(\"geocoded_addresses.rds\")\n\n\n# -------------- Spatial Visualization --------------\n# Convert to geocoded addresses to sf object\nfinal_census_sf &lt;- st_as_sf(\n    final_census_df,\n    coords = c(\"long\", \"lat\"),\n    crs = 4326\n)\n\n# Get total population by census tract for Santa Barbara County\nsb_pop_2023 &lt;- get_acs(\n    geography = \"tract\",\n    variables = \"B01003_001\", # Total population variable\n    state = \"CA\",\n    county = \"Santa Barbara\",\n    year = 2023,\n    geometry = TRUE\n) %&gt;%\n    st_transform(crs = 4326)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=======                                                               |  11%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |==============                                                        |  21%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  59%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |======================================================================| 100%\n\n# Join voters to tracts and calculate party percentages\nvoters_with_tract &lt;- st_join(final_census_sf, sb_pop_2023)\n\nparty_by_tract &lt;- voters_with_tract %&gt;%\n    st_drop_geometry() %&gt;%\n    group_by(GEOID) %&gt;%\n    mutate(tract_total = n()) %&gt;%\n    group_by(GEOID, party_code, tract_total) %&gt;%\n    summarize(count = n()) %&gt;%\n    mutate(percentage = count / tract_total * 100) %&gt;%\n    ungroup()\n\n# Create a dataset with relative Dem-Rep percentages (excluding other parties)\ntwo_party_comparison &lt;- party_by_tract %&gt;%\n  filter(party_code %in% c(\"DEM\", \"REP\")) %&gt;%\n  group_by(GEOID) %&gt;%\n  mutate(two_party_total = sum(count)) %&gt;%\n  # Recalculate percentages based only on Dem + Rep voters\n  mutate(two_party_pct = count / two_party_total * 100) %&gt;%\n  select(GEOID, party_code, two_party_pct) %&gt;%\n  pivot_wider(\n    names_from = party_code,\n    values_from = two_party_pct\n  ) %&gt;%\n  mutate(diff = DEM - REP)\n\n# Join the difference data to the geometry\ntract_diff_map &lt;- sb_pop_2023 %&gt;%\n  select(GEOID, geometry) %&gt;%\n  left_join(two_party_comparison, by = \"GEOID\") %&gt;%\n  filter(!is.na(diff))\n\n# Create the divergent map\nggplot() +\n  geom_sf(data = tract_diff_map, aes(fill = diff)) +\n  scale_fill_gradient2(\n    low = party_colors[\"REP\"],\n    mid = \"#FFFFFF\",               \n    high = party_colors[\"DEM\"],\n    midpoint = 0,\n    name = \"Dem-Rep Difference (%)\"\n  ) +\n  labs(\n    title = \"Democratic vs. Republican Voter Distribution by Census Tract\",\n    subtitle = \"Percentage difference between parties (excluding other affiliations)\"\n  ) +\n  theme_void()\n\n\n\n\n\n# -------------- Waffle Chart --------------\n# Create waffle chart of party distribution\nwaffle_counts &lt;- full_file %&gt;%\n    mutate(\n        party_code = if_else(\n            party_code %in% c(\"DEM\", \"REP\", \"NPP\"),\n            party_code,\n            \"Other\"\n        )\n    ) %&gt;%\n    count(party_code) %&gt;%\n    mutate(\n        party_code = factor(\n            party_code,\n            levels = c(\"DEM\", \"REP\", \"NPP\", \"Other\")\n        )\n    )\n\n# Limit total squares for better display\nmax_squares &lt;- 200\nif (sum(waffle_counts$n) &gt; max_squares) {\n    waffle_counts &lt;- waffle_counts %&gt;%\n        mutate(n = round(n * max_squares / sum(n)))\n}\n\n# Create waffle chart\nggplot(waffle_counts, aes(fill = party_code, values = n)) +\n    geom_waffle(color = \"white\", size = 0.5, n_rows = 10) +\n    scale_fill_manual(values = party_colors) +\n    coord_fixed() +\n    theme_void() +\n    labs(\n        title = \"Party Distribution in Santa Barbara County\",\n        fill = \"Party\"\n    )"
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "",
    "text": "Link to repo (more content available here!)"
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#about",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#about",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "About",
    "text": "About\nPurpose: This analysis explores the 2017 Thomas Fire using two main approaches:\n\nCreating visualizations of the fire perimeter and burn area using Landsat satellite imagery\nAnalyzing the types and distribution of land cover affected by the fire\n\nUsing historical fire perimeter data from CalFire combined with Landsat imagery, we create detailed maps showing both true-color and false-color visualizations of the Thomas Fire area. Here we use historical fire perimeter data from CalFire to obtain the perimeter of the 2017 Thomas Fire. Using provided Landsat imagery and the fire perimeter, we create a map showing the perimeter of the 2017 Thomas Fire in relation to Santa Barbara County.\nWe then analyze land cover data to understand what types of ecosystems were impacted by the fire. Using the GAP/LANDFIRE National Terrestrial Ecosystems data for 2011 from the US Geological Survey (USGS), we calculate the area of each land cover type within the fire perimeter and compare it to the total area of each land cover type in Santa Barbara County.\nHighlights:\n\nCleaning data\nLabel-based selection\nGeospatial file creation\nrioxarray raster file manipulation\nTrue color imagery plotting\nFalse color imagery plotting\nPixel-based land cover calculations\nArea and percentage computations\n\nDataset Descriptions:\nSection 1:\nThe landsat data is a simplified collection of bands from the Landsat Collection 2 Level-2 atmospherically corrected surface reflectance data, collected by the Landsat 8 satellite. This data was retrieved from the Microsoft Planetary Computer data catalogue and pre-processed to remove data outside land and coarsen the spatial resolution.\nCalifornia’s Fire and Resource Assessment Program (FRAP) maintains a comprehensive database of historical fire perimeters throughout the state, covering both public and private lands. This GIS dataset is updated annually through a collaborative effort between FRAP and several federal agencies - the U.S. Forest Service Region 5, Bureau of Land Management, National Park Service, and Fish and Wildlife Service.\nSection 2:\nThe GAP/LANDFIRE National Terrestrial Ecosystems data for 2011 @davidson_gaplandfire_2016, from the US Geological Survey (USGS) is a categorical raster with a 30 m x 30 m pixel resolution representing highly thematically detailed land cover map of the U.S.\nThe class names and corresponding codes have been saved to a separate CSV to simplify access. Further information on how to access the classes directly from the data are available in the MPC catalog.\nPlease see end for references\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport rioxarray as rioxr\nfrom shapely import box\nfrom IPython.display import Image"
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#data-loading-and-initial-processing",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#data-loading-and-initial-processing",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "Data Loading and Initial Processing",
    "text": "Data Loading and Initial Processing\n\n# Load fire perimeter data from a geodatabase file\nfire_perimeter = gpd.read_file(os.path.join(\"data\", \"fire23_1.gdb\"))\nfire_perimeter.head()\n\n# Convert columns to lowercase for consistency\nfire_perimeter.columns = fire_perimeter.columns.str.lower()\n\n\nprint(\n    f\"Fire Perimeter CRS: {fire_perimeter.crs} \\nIs this projected?: {fire_perimeter.crs.is_projected}\"\n)\n\nFire Perimeter CRS: EPSG:3310 \nIs this projected?: True\n\n\nThe fire perimeter data uses EPSG: 3310, which is a projected coordinate reference system specifically designed for California."
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#thomas-fire-perimeter",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#thomas-fire-perimeter",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "Thomas Fire Perimeter",
    "text": "Thomas Fire Perimeter\nLet’s create a mask of the Thomas Fire perimeter. First, filter the historical fire perimeters dataset to the 2017 Thomas Fire and then save as a geospatial file in the data/ directory.\n\n# Filter to the 2017 Thomas Fire\nthomasfire = fire_perimeter.loc[\n    (fire_perimeter[\"fire_name\"] == \"THOMAS\") & (fire_perimeter[\"year_\"] == 2017)\n]\n\nCreate a visualization of the Thomas Fire perimeter using geopandas and matplotlib.\n\n# Plot the perimeter\nfig, ax = plt.subplots(figsize=(10, 8))\nax.axis(\"off\")\nthomasfire.plot(\n    ax=ax,\n    color=\"firebrick\",\n)\n\n# Set title\nax.set_title(\"Thomas Fire (2017) Perimeter Mask\")\n\n# Add source information with adjusted position\nplt.figtext(0.01, 0.02, \"Data: CAL FIRE\", ha=\"left\", fontsize=10)\n\n# Adjust layout\nplt.tight_layout()\nplt.subplots_adjust(bottom=0.05)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Save file to the data folder in `.geojson` format.\nthomasfire.to_file(\"data/thomasfire.geojson\", driver=\"GeoJSON\")\n\nGeoJSON is an open standard format that can represent a variety of geometries. It is based on JavaScript Object Notation (JSON), and is commonly used to store spatial data."
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#landsat-data-processing",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#landsat-data-processing",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "Landsat Data Processing",
    "text": "Landsat Data Processing\nTo plot true and false color images, we will use the Landsat 8 satellite imagery from January 26, 2018, shortly after the Thomas Fire. The data includes several spectral bands:\n\nRed, Green, Blue (visible light)\nNIR (Near Infrared)\nSWIR (Short-wave Infrared)\n\nThe landsat data is accessed from UCSB Bren’s workbench-1 server at:\n/courses/EDS220/data/hwk4_landsat_data landsat8-2018-01-26-sb-simplified.nc\n\n# Import data\nroot = os.path.join(\"/\", \"courses\", \"EDS220\", \"data\", \"hwk4_landsat_data\")\n\nfp = os.path.join(root, \"landsat8-2018-01-26-sb-simplified.nc\")\n\nlandsat = rioxr.open_rasterio(fp)\n\nLet’s do some preliminary data exploration to understand the structure of the data.\n\n# Check CRS of data and dimensions\nprint(\n    f\"{'Landsat 8 CRS:':&lt;25} {landsat.rio.crs}\\n\"\n    f\"{'Is it projected?':&lt;25} {landsat.rio.crs.is_projected}\\n\"\n    f\"{'Sizes of dimensions:':&lt;25} {dict(landsat.sizes)}\"\n)\n\nLandsat 8 CRS:            EPSG:32611\nIs it projected?          True\nSizes of dimensions:      {'band': 1, 'x': 870, 'y': 731}\n\n\n\nprint(landsat)\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...\n\n\nThe landsat dataset has three dimensions: band, x, and y; it has variables for red, green, blue, near infrared 0.8, and short-wave infrared 2.2 bands. The coordinate reference system is EPSG: 32611 (projected).\nThe band dimension makes our raster three dimensional and is unnecessary. We can go ahead and “squeeze” the raster to simplify it:\n\n# Drop the band dimension of the data\nlandsat = landsat.squeeze().drop_vars(\"band\")"
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#true-color-image",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#true-color-image",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "True color image",
    "text": "True color image\nUsing the red, green, and blue bands from the landsat data, we can create a true-color visualization of Santa Barbara County.\n\n# Create true color visualization using red, green, blue bands\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nThe plot is black and white; this is because there are a large number of high RGB values from clouds skewing the color scale for the plot.\nPassing the robust=True parameter in plt.imshow prevents outliers from washing out the color scale of the plot. robust=True uses the 2nd and 98th percentiles of the data to compute the color limits. The adjusted output takes into account that the RGB values of the clouds are outliers.\n\n# Set `robust=True` for better color scale when plotting\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\nNow, our image more closely resembles the true color of the landscape."
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#false-color-image",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#false-color-image",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "False color image",
    "text": "False color image\nFalse color imagery is a useful tool for monitoring wildfire impacts. By assigning infrared bands to visible colors, these images highlight vegetation health, burn severity, and the extent of fire scars. This approach helps researchers and land managers assess recovery efforts, identify high-risk areas, and plan restoration strategies. To create a false color image, we will use the short wave infrared, near-infrared, and red bands from the Landsat data.\n\n# Create false color visualization using SWIR, NIR and red bands\nlandsat[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\nTo add the Thomas Fire perimeter we created earlier, import the file and make sure the CRS for landsat matches. This step is crucial because:\n\nDifferent data sources often use different CRS\nMismatched CRS can cause spatial misalignment\nEPSG:3310 (California Albers) is optimal for California analysis\n\n\n# Import the Thomas Fire perimeter\nthomasfire = gpd.read_file(os.path.join(\"data\", \"thomasfire.geojson\"))\n\n# Reproject Landsat data to match fire perimeter CRS (coordinate reference system)\nthomasfire.crs\nlandsat = landsat.rio.reproject(\"EPSG:3310\")\nassert landsat.rio.crs == thomasfire.crs\n\nLet’s create a clipped version to use for plotting.\n\n# Create a false color image and clip it for plotting\nfalsecolor_thomasfire = landsat[[\"swir22\", \"nir08\", \"red\"]].to_array()\n\nfalsecolor_clip = falsecolor_thomasfire.rio.clip_box(*thomasfire.total_bounds)"
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#plot-false-color-image-with-thomas-fire-perimeter",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#plot-false-color-image-with-thomas-fire-perimeter",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "Plot False Color Image with Thomas Fire Perimeter",
    "text": "Plot False Color Image with Thomas Fire Perimeter\n\n# Create a map showing the false color image together with the Thomas Fire perimeter.\nfig, ax = plt.subplots(figsize=(10, 8))\n\nax.axis(\"off\")\n\nfalsecolor_thomasfire.plot.imshow(ax=ax, robust=True)\nthomasfire.geometry.boundary.plot(\n    ax=ax, color=\"darkred\", linewidth=1.5, label=\"Fire Perimeter\"\n)\n\nax.legend(fontsize=\"small\")\nplt.tight_layout()\nplt.subplots_adjust(bottom=0.05)\n\nax.set_title(\"Thomas Fire (2017) Perimeter Map\")\n\nplt.figtext(0.01, 0.015, \"Data: NASA Landsat & CalFire\", ha=\"left\", fontsize=10)\n\nplt.show()\n\n\n\n\n\n\n\n\nLet’s crop the map to see the fire scar more clearly.\n\n# Create a clipped map showing the false color image and the Thomas Fire perimeter\nfig, ax = plt.subplots(figsize=(10, 8))\n\nax.axis(\"off\")\n\nfalsecolor_clip.plot.imshow(ax=ax, robust=True)\nthomasfire.geometry.boundary.plot(\n    ax=ax, color=\"darkred\", linewidth=1.5, label=\"Fire Perimeter\"\n)\n\nax.legend(fontsize=\"small\")\nplt.tight_layout()\nplt.subplots_adjust(bottom=0.05)\n\nax.set_title(\"Thomas Fire (2017) Perimeter - Clipped Map\")\n\nplt.figtext(0.01, 0.12, \"Data: NASA Landsat & CalFire\", ha=\"left\", fontsize=10)\n\nplt.show()"
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#analysis-of-false-color-maps",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#analysis-of-false-color-maps",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "Analysis of False Color Maps",
    "text": "Analysis of False Color Maps\nThe above maps use false color satellite imagery to display the burn scar from the 2017 Thomas Fire and its perimeter. Shortwave infrared (SWIR) is plotted in red, near infrared (NIR) in green, and the red band in blue. Newly burned soil reflects SWIR light strongly, and plants containing water reflect NIR strongly, which makes this false color image helpful for visualizing fire effects."
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#compute-land-cover-statistics",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#compute-land-cover-statistics",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "Compute land cover statistics",
    "text": "Compute land cover statistics\nNext, we will compute land cover statistics within the Thomas Fire perimeter in the following steps:\n\nUse the numpy function np.unique() to get the number of pixels per class in lulc_clip\n\n\nnp.unique(lulc, return_counts=True)[1]\n\narray([1927870,    6856,     361,  133704,    3638,   23150,    2907,\n          4974,    3727,   60203,    5102,   75925,     378,   11098,\n            29,      98,   64072,   69700,  183963,  454489,   88504,\n           799,     750,     684,      28,      90,     865,     262,\n          1329,      54,      44,      27,     298,      24,      15,\n            43,       7,   18996,    2181,     485,      13,      20,\n            10,    1858,   40653,    3782,     829,      58])\n\n\n\nCreate a data frame pix_counts with two columns: the code numbers for the pixels in lulc_clip and the number of pixels corresponding to each code\n\n\npix_counts = {\n    \"Class\": np.unique(lulc),\n    \"counts\": np.unique(lulc, return_counts=True)[1],\n}\n\npix_counts = pd.DataFrame(pix_counts)\npix_counts.head()\n\n\n\n\n\n\n\n\nClass\ncounts\n\n\n\n\n0\n0\n1927870\n\n\n1\n39\n6856\n\n\n2\n40\n361\n\n\n3\n41\n133704\n\n\n4\n42\n3638\n\n\n\n\n\n\n\n\nUse the labels data frame to add the class names to the codes in the pix_counts data frame. Store the resulting data frame as classes.\n\n\n# Rename the 'code' column in labels to match 'Class' in pix_counts\nlabels = labels.rename(columns={\"code\": \"Class\"})\n\n# Merge the dataframes, excluding rows where Class = 0\nclasses = pd.merge(pix_counts[pix_counts[\"Class\"] != 0], labels, on=\"Class\", how=\"left\")\nclasses.head()\n\n\n\n\n\n\n\n\nClass\ncounts\nclass_label\n\n\n\n\n0\n39\n6856\nCalifornia Central Valley Mixed Oak Savanna\n\n\n1\n40\n361\nCalifornia Coastal Closed-Cone Conifer Forest ...\n\n\n2\n41\n133704\nCalifornia Coastal Live Oak Woodland and Savanna\n\n\n3\n42\n3638\nCalifornia Lower Montane Blue Oak-Foothill Pin...\n\n\n4\n43\n23150\nCentral and Southern California Mixed Evergree...\n\n\n\n\n\n\n\n\nWhat area within the fire perimeter (in km^2) was estimated to be developed? The raster has a resolution of 30m.\n\n\n# Area of the Thomas Fire in square kilometers\nthomasfire_area_km = thomasfire.area / 1e6\nthomasfire_area_km\n\n0    1140.367254\ndtype: float64\n\n\n\n# Find the area of classes labeled as \"Developed\". These are located at 581-584.\narea_km_developed = (\n    classes[classes.Class.isin([581, 582, 583, 584])].counts.sum() * 30 * 30 / 1e6\n)\narea_km_developed\n\n40.7898\n\n\n\nWhat percent of the total area burned was developed?\n\n\nprint((area_km_developed / thomasfire_area_km * 100)[0], \"% \")\n\n3.5769003248981366 % \n\n\n\nStore the total number of pixels within the fire perimeter as a variable total_pixels\n\n\ntotal_pixels = classes.counts.sum()\ntotal_pixels\n\n1267082\n\n\n\nAdd the percentage of area covered by each class as a new column percentage to the classes data frame. Sort the data frame by percentage coverage in descending order.\n\n\nclasses[\"percent\"] = classes[\"counts\"] / classes[\"counts\"].sum() * 100\nclasses = classes.sort_values(by=\"percent\", ascending=False)\n\n\nCreate a horizontal bar plot showing the classes with more than 1% land cover in decreasing order.\n\n\n# Filter for classes with &gt;1% coverage and sort by percent in descending order\nfiltered_classes = classes[\n    (classes[\"percent\"] &gt; 1) & (classes[\"Class\"] != 0)\n].sort_values(\"percent\", ascending=True)\n\n# Create the horizontal bar plot\nplt.figure(figsize=(12, 8))\nplt.barh(\n    filtered_classes[\"class_label\"],\n    filtered_classes[\"percent\"],\n    height=0.5,\n    color=\"lightblue\",\n    edgecolor=\"black\",\n)\n\nplt.xlabel(\"Percent Land Cover\")\nplt.ylabel(\"Class Label\")\nplt.title(\n    \"Distribution of Land Cover within the Thomas Fire Perimeter, \\nLand Cover (&gt;1%)\",\n    fontsize=16,\n)\n\n# Adjust margins\nplt.margins(x=0.2)\n\nfor i, v in enumerate(filtered_classes[\"percent\"]):\n    plt.text(v, i, f\" {v:.1f}%\", va=\"center\")\n\nplt.xticks(rotation=0)\nplt.yticks(rotation=0)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#conclusion",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#conclusion",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "Conclusion",
    "text": "Conclusion\nHere we see the Thomas Fire predominantly affected coastal and chaparral ecosystems, with over 56% of the burned area consisting of coastal scrub and mixed chaparral vegetation types. Oak woodlands and savannas made up another significant portion, accounting for about 18% of the affected area. Only a small percentage of the burned area was developed land, indicating that the fire primarily affected natural ecosystems. Understanding the distribution of land cover types affected by the fire can help inform future land management decisions and restoration efforts in the area, and plan future fire management strategies. These findings highlight the importance of managing and protecting California’s coastal scrub and chaparral ecosystems, which are naturally adapted to fire but face increasing pressure from climate change and altered fire regimes."
  },
  {
    "objectID": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#references",
    "href": "posts/2024-12-04-thomas-fire-visualization/thomas-fire-blogpost.html#references",
    "title": "Thomas Fire: Perimeter Visualization & Land Cover Statistics",
    "section": "References",
    "text": "References\n\nFire Resource and Assessment Program. (2024). Historical Fire Perimeters. CalFire. https://www.fire.ca.gov/what-we-do/fire-resource-assessment-program/fire-perimeters. Accessed: November 23, 2024.\nNASA Landsat 8 (2024). Landsat Collection 2 Level-2 Science Products. Microsoft Planetary Computer. https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Accessed: November 23, 2024.\nU.S. Geological Survey. (2016). GAP/LANDFIRE National Terrestrial Ecosystems Data 2011. USGS. https://www.sciencebase.gov/catalog/item/573cc51be4b0dae0d5e4b0c5. Accessed: November 23, 2024.\nGalaz-Garcia, Carmen. (2024). EDS 220 Assignment 4. UCSB MEDS. https://meds-eds-220.github.io/MEDS-eds-220-course/assignments/assignment4.html. Accessed: November 23, 2024."
  },
  {
    "objectID": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html",
    "href": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html",
    "title": "Ocean Chemistry and Santa Barbara Channel Macrocystis Pyrifera Populations",
    "section": "",
    "text": "Santa Barbara’s coastal waters host some of the most productive marine ecosystems on earth, Macrocystis pyrifera, or giant kelp forests. Kelp are a keystone species, and provide food, shelter and protection for all kinds of marine life, including commercially valuable fisheries. According to NOAA, factors influencing kelp forest growth include nutrients, light levels, temperatures, and ocean currents. Research by Smith et. al newly found that kelp use urea, in addition to ammonium, nitrate, dissolved organic nitrogen as nutrients for growth.\nIn this analysis, I would like to examine the relationship between ocean chemistry and kelp forest biomass, and develop a model for nutrient growth factors on biomass.\nThis exercise was produced as a part of the UCSB MEDS Program for EDS 222: Statistics for Environmental Data Science, taught by Dr. Max Czapanskiy.\n\n\n\n1. SBC LTER: Reef: Annual time series of biomass for kelp forest species, ongoing since 2000\n\nThese data are annual estimates of biomass of approximately 225 taxa of reef algae, invertebrates and fish in permanent transects at 11 kelp forest sites in the Santa Barbara Channel (2-8 transects per site). Abundance is measured annually (as percent cover or density, by size) and converted to biomass (i.e., wet mass, dry mass, decalcified dry mass, ash free dry mass) using published taxon-specific algorithms. Data collection began in summer 2000 and continues annually in summer to provide information on community structure, population dynamics and species change.\n\n\n\n\nSBC LTER Reef Sites\n\n\n2. SBC LTER: Ocean: Ocean Currents and Biogeochemistry: Nearshore water profiles (monthly CTD and chemistry), ongoing since 2000\n\nThese data contain water chemistry measurements taken monthly at these reefs in the nearshore areas of the Santa Barbra Channel, CA, USA: Arroyo Quemado, Bullito, Naples, Arroyo Burro, Mohawk and Carpinteria. Measurements include standard CTD parameters, nutrients, pigments, particulate CN, total dissolved N and P, stable isotopes of C and N (not all parameters are measured at all stations). Sampling began in November 2000. Starting in February 2003, a SBE19-Plus with a rosette sampler was used. Some stations are sampled only occasionally.\n\n\n\n\nSBC LTER Ocean Bottle Sites\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(here)\nlibrary(readtext)\nlibrary(janitor)\n\ntheme_set(theme_bw())\nset.seed(42)\n\n\n\n\nCode\n# Read in kelp and ocean chemistry data\nspecies &lt;- read_csv(here::here(\n  \"posts/2024-12-12-ocean-chem-kelp/data/Annual_All_Species_Biomass_at_transect_20240823.csv\"), na = \"-99999\") %&gt;%\n  janitor::clean_names()\n\nocean_chem &lt;- read.table(here::here(\"posts/2024-12-12-ocean-chem-kelp/data/LTER_monthly_bottledata_20240821.txt\"), \n  header = TRUE, sep = \";\", na = c(\"BDL\", \"99999\")) %&gt;% # `BDL` = below detection level\n  janitor::clean_names()\n\n# Filter to Giant kelp (Macrocystis pyrifera)\nkelp &lt;- species %&gt;%\n  filter(scientific_name == \"Macrocystis pyrifera\")\n\n\nThe variables I plan to use for ocean chemistry are (in units of micromoles per liter):\n\nno2_no3_umol_l = concentration of the sum of nitrate and nitrite\npon_umol_l = concentration of particulate organic nitrogen\ntdn_umol_l= concentration of dissolved nitrogen\nammonia_umol_l= concentration of ammonium\nurea_umol_l= concentration of urea\n\nThe variables I plan to use for kelp biomass are:\n\nwm_gm2 = areal wet mass of individuals or colony in grams per square meter\ndensity = density taxon per squared meter in number per square meter\n\nNote: there are other measures of biomass in ocean_chem. However, they are just linear transformations of wet mass.\n\n\n\n\n\nCode\n# Summarize kelp data to monthly averages\nmonthly_kelp_data &lt;- kelp %&gt;%\n  group_by(year, month, site) %&gt;%\n  summarise(across(where(is.numeric), mean, na.rm = TRUE)) %&gt;%\n  mutate(date = as.Date(paste(year, month, \"01\", sep=\"-\")))\n\n# Summarize ocean chem data to monthly averages\nmonthly_ocean_data &lt;- ocean_chem %&gt;%\n  mutate(date = as.Date(yyyy_mm_dd),\n         year = lubridate::year(yyyy_mm_dd),\n         month = lubridate::month(yyyy_mm_dd)) %&gt;%\n  mutate(site = case_when(\n    station %in% c(\"QI\", \"QM\", \"QO\", \"QR\") ~ \"AQUE\", # match site names at both datasets\n    station %in% c(\"CI\", \"CO\", \"CR\") ~ \"CARP\",\n    station %in% c(\"MI\", \"MK\") ~ \"MOHK\",\n    station %in% c(\"NI\", \"NO\", \"NR\") ~ \"NAPL\",\n    station %in% c(\"BI\", \"BO\", \"BR\") ~ \"BULL\",\n    station %in% c(\"AB\") ~ \"ABUR\"\n  )) %&gt;%\n  group_by(year, month, site) %&gt;%\n  summarise(\n    across(where(is.numeric), mean),\n    n = dplyr::n()) %&gt;%\n  mutate(date = as.Date(paste(year, month, \"01\", sep=\"-\")))\n\n# Plot monthly average weight data\nggplot(monthly_kelp_data, aes(date, wm_gm2)) +\n  geom_line(color = \"#6d8c23\") +\n  geom_point() +\n  facet_wrap(~site) +\n  scale_x_date(date_breaks = \"4 years\",\n               date_labels = \"%Y\") +\n  labs(title = \"Monthly Average Giant Kelp Biomass by Site\",\n       x = \"Date\",\n       y = \"Wet Mass (g/m²)\") +\n  theme(axis.text.x = element_text(size = 6), angle = 45, hjust = 1)\n\n\n\n\n\n\n\n\n\nCode\n# Check which sites have monthly ocean chemistry data\nggplot(monthly_ocean_data, aes(date, n)) +\n  geom_line(color = \"#6d8c23\") +\n  geom_point(size = 0.1) +\n  facet_wrap(~site) +\n  scale_x_date(date_breaks = \"4 years\",\n               date_labels = \"%Y\") +\n  scale_y_continuous(expand = expansion(c(0, 0))) +\n  labs(title = \"Number of Ocean Chemistry Measurements by Site\",\n       x = \"Date\",\n       y = \"Number of Measurements\") +\n  theme(axis.text.x = element_text(size = 6), angle = 45, hjust = 1)\n\n\n\n\n\n\n\n\n\nNote that there is a significant amount of missing data.\n\n\nCode\n# Join kelp and ocean chemistry datasets\njoined_data &lt;- left_join(\n  monthly_kelp_data, \n  monthly_ocean_data, \n  by = join_by(year, month, site, date)) %&gt;% \n  mutate(\n    site = as.factor(site),\n    pon_umol_l_log = log1p(pon_umol_l),\n    wm_gm2_log = log1p(wm_gm2))\n\n\nAfter grouping and summarizing the data, we are left with very few data points. There are NO instances that account for all of the ocean chemistry and kelp biomass variables initially identified for analysis.\nLooking at the joined data, the column with the most complete data from the original variables seems to be pon_umol_l.\n\n\n\n\n\nCode\n# Plot wet weight as a function of time\nggplot(joined_data, aes(date, wm_gm2)) +\n  geom_line(color = \"#6d8c23\") +\n  geom_point(size = 0.1) +\n  facet_wrap(~site) +\n  scale_x_date(date_breaks = \"4 years\",\n               date_labels = \"%Y\") +\n  scale_y_continuous(expand = expansion(c(0, 0))) +\n  labs(title = \"Giant Kelp Wet Mass Over Time by Site\",\n       x = \"Date\", \n       y = \"Wet Mass (g/m²)\") +\n  theme(axis.text.x = element_text(size = 6), angle = 45, hjust = 1)\n\n\n\n\n\n\n\n\n\nCode\n# Plot particulate organic nitrogen concentration as a function of time\nggplot(joined_data, aes(date, pon_umol_l)) +\n  geom_line(color = \"#6d8c23\") +\n  geom_point(size = 0.1) +\n  facet_wrap(~site) +\n  scale_x_date(date_breaks = \"4 years\",\n               date_labels = \"%Y\") +\n  scale_y_continuous(expand = expansion(c(0, 0))) +\n  labs(title = \"Particulate Organic Nitrogen Concentration Over Time by Site\",\n       x = \"Date\",\n       y = \"PON Concentration (μmol/L)\") +\n  theme(axis.text.x = element_text(size = 6), angle = 45, hjust = 1)\n\n\n\n\n\n\n\n\n\nCode\n# Plot particulate organic nitrogen as a function of wet mass\nggplot(joined_data, aes(wm_gm2, pon_umol_l)) +\n  geom_point(size = 1,\n             color = \"#6d8c23\") +\n  facet_wrap(~site) +\n  scale_y_continuous(expand = expansion(c(0, 0))) +\n  labs(title = \"PON Concentration vs Kelp Biomass by Site\",\n       x = \"Wet Mass (g/m²)\",\n       y = \"PON Concentration (μmol/L)\")\n\n\n\n\n\n\n\n\n\nCode\n# Plot particulate organic nitrogen as a function of log wet mass\nggplot(joined_data, aes(wm_gm2_log, pon_umol_l)) +\n  geom_point(size = 1,\n             color = \"#6d8c23\") +\n  facet_wrap(~site) +\n  scale_y_continuous(expand = expansion(c(0, 0))) +\n  labs(title = \"PON Concentration vs Log Kelp Biomass by Site\",\n       x = \"Log Wet Mass (g/m²)\",\n       y = \"PON Concentration (μmol/L)\")\n\n\n\n\n\n\n\n\n\n\n\n\nIs there a relationship between biomass and particulate organic nitrogen (PON) concentration?\n\n\nCode\n# 1. Biomass and particulate organic nitrogen\nmodel_wm &lt;- lm(formula = wm_gm2 ~ pon_umol_l + site, \n               data = joined_data) \nmodel_wm %&gt;% \n  summary()\n\n\n\nCall:\nlm(formula = wm_gm2 ~ pon_umol_l + site, data = joined_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3648.9 -1378.2  -418.3  1079.4  5162.0 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1246.88     673.76   1.851  0.06743 .  \npon_umol_l    147.54      53.95   2.735  0.00749 ** \nsiteNAPL      143.32     660.54   0.217  0.82870    \nsiteABUR    -1252.58     688.31  -1.820  0.07204 .  \nsiteAQUE      704.76     666.46   1.057  0.29307    \nsiteMOHK     3186.67     695.94   4.579 1.46e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2020 on 92 degrees of freedom\n  (166 observations deleted due to missingness)\nMultiple R-squared:  0.3592,    Adjusted R-squared:  0.3243 \nF-statistic: 10.31 on 5 and 92 DF,  p-value: 7.175e-08\n\n\nCode\n# 2. Log biomass and particulate organic nitrogen\nmodel_wm_log &lt;- lm(formula = wm_gm2_log ~ pon_umol_l + site, \n                   data = joined_data) \nmodel_wm_log %&gt;% \n  summary()\n\n\n\nCall:\nlm(formula = wm_gm2_log ~ pon_umol_l + site, data = joined_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.7046 -0.6219  0.3389  0.8050  3.1095 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.57754    0.48030  13.695  &lt; 2e-16 ***\npon_umol_l   0.06801    0.03846   1.768  0.08032 .  \nsiteNAPL     0.16902    0.47088   0.359  0.72046    \nsiteABUR    -1.38850    0.49067  -2.830  0.00572 ** \nsiteAQUE     0.45671    0.47509   0.961  0.33892    \nsiteMOHK     1.49788    0.49611   3.019  0.00328 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.44 on 92 degrees of freedom\n  (166 observations deleted due to missingness)\nMultiple R-squared:  0.2987,    Adjusted R-squared:  0.2605 \nF-statistic: 7.836 on 5 and 92 DF,  p-value: 3.512e-06\n\n\nCode\n# 3. Density and particulate organic nitrogen\nmodel_wm_density &lt;- lm(formula = density ~ pon_umol_l + site, \n                       data = joined_data) \nmodel_wm_density %&gt;% \n  summary()\n\n\n\nCall:\nlm(formula = density ~ pon_umol_l + site, data = joined_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.7742 -2.6087 -0.6179  1.8569 10.1785 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   1.7383     1.2152   1.430  0.15598    \npon_umol_l    0.3174     0.0973   3.261  0.00156 ** \nsiteNAPL      0.6812     1.1914   0.572  0.56885    \nsiteABUR     -1.8348     1.2414  -1.478  0.14285    \nsiteAQUE      1.4354     1.2020   1.194  0.23551    \nsiteMOHK      7.8533     1.2552   6.256 1.23e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.644 on 92 degrees of freedom\n  (166 observations deleted due to missingness)\nMultiple R-squared:  0.4621,    Adjusted R-squared:  0.4328 \nF-statistic: 15.81 on 5 and 92 DF,  p-value: 3.266e-11\n\n\n1. Biomass Model model_wm\nThere is a significant positive relationship between PON and kelp biomass (p = 0.00749). For every one μmol/L increase in PON concentration, kelp wet mass increases by 147.54 grams/square meter when the reference site is BULL. Consistent with the “Monthly Average Giant Kelp Biomass by Site” plot, the MOHK site has significantly higher biomass than the other sites (coef = 3187.67, p = 1.46e-5). The model explains about 32.4% of the variation in biomass (not great).\n2. Log Biomass Model model_wm_log\nThere is a marginally significant positive relationship between PON and log-transformed kelp biomass (p = 0.080). For every one μmol/L increase in PON concentration, log kelp wet mass increases by 0.068 units when the reference site is BULL. The ABUR site shows significantly lower biomass (coef = -1.389, p = 0.006) while MOHK shows significantly higher biomass (coef = 1.498, p = 0.003) compared to other sites. The model explains about 26.1% of the variation in log biomass (poor fit).\n3. Biomass Density Model model_wm_density\nThere is a significant positive relationship between PON and kelp density (p = 0.002). For every one μmol/L increase in PON concentration, kelp density increases by 0.317 individuals per square meter when the reference site is BULL. Similar to the biomass models, the MOHK site shows significantly higher density than other sites (coef = 7.853, p &lt; 0.001). This model has the best fit of the three, explaining about 43.3% of the variation in density, but still is not great.\n\n\n\nHypotheses:\n\nH0: Particulate organic nitrogen has no effect on kelp biomass\nHA: Particulate organic nitrogen has an effect on kelp biomass\n\n\n\nCode\n# Get observed coefficient for pon_umol_l\nobserved_coef &lt;- coef(summary(model_wm))[\"pon_umol_l\", \"t value\"]\n\n# Create randomizations\nnull_dist &lt;- replicate(1000, {\n  rand_joined_data &lt;- joined_data %&gt;% \n    ungroup() %&gt;% \n    mutate(pon_umol_l = sample(pon_umol_l))\n  \n  rand_model &lt;- lm(wm_gm2 ~ pon_umol_l + site, data = rand_joined_data)\n  coef(summary(rand_model))[\"pon_umol_l\", \"t value\"]\n})\n\n# Calculate p-value (two-sided test)\np_value &lt;- mean(abs(null_dist) &gt;= abs(observed_coef))\n\n# Plot the null distribution\nnull_dist_df &lt;- data.frame(t_stat = null_dist)\nggplot(null_dist_df, aes(x = t_stat)) +\n  geom_histogram(binwidth = 0.2, \n                 fill = \"#6d8c23\", \n                 color = \"white\") +\n  geom_vline(xintercept = observed_coef, color = \"orchid\", linewidth = 1) +\n  labs(title = \"Null Distribution of PON Coefficient t-statistics\",\n       x = \"t-statistic\",\n       y = \"Count\")\n\n\n\n\n\n\n\n\n\nCode\ncat(\"Randomization test p-value:\", p_value, \"\\n\")\n\n\nRandomization test p-value: 0.003 \n\n\nCode\ncat(\"Observed t-statistic:\", observed_coef, \"\\n\")\n\n\nObserved t-statistic: 2.734869 \n\n\nThis randomization test shuffled the data n = 1000 times to determine what the point estimate (t-statistic) would be if it occurred by chance. 0nly 0.3% of the time would a value of t = 2.37 be produced as chance. At a threshold of alpha = 0.05, we can reject our null hypothesis and state that PON has a positive effect on kelp wet mass.\nThe observed t-statistic is 2.73, which means that the estimated coefficient is 2.73 standard errors away from zero. In the figure, the null distribution shows us what we would expect if there was no relationship between PON and biomass (measured by density). The purple line falls outside of the majority of the distribution, which tells us that there is a strong relationship between PON and density.\n\n\n\nDue to incomplete data, I could not perform my intended analysis. The ocean chemistry and kelp data were inconsistently collected across sites and months, leaving very few usable data points after cleaning.\nThe model likely suffers from omitted variable bias. While prior research has established that temperature, currents, and light levels affect kelp growth, my model only included PON and site as variables, excluding other nutrients and physical variables.\nAutocorrelation may have affected the results because samples were taken at monthly intervals, and ecological conditions typically carry over from one month to the next. This violation of independence could lead to underestimated standard errors and overstated significance in the statistical results. However, techniques to reduce autocorrelation, such as a temporal lag model, were not feasible given the substantial missing data, which included gaps of several months in the joined dataset.\nOverall, the results of my models should not be considered reliable due to the significant data gaps. I had overestimated the completeness of the LTER data for this research question.\nFor future research, I would like to analyze Thomas Fire effects on kelp growth using a more complete ocean chemistry dataset. Researchers at UCSB discovered that wildfire ash from the 2017 Thomas Fire resulted in significant additions of dissolved nutrients, including inorganic and organic nitrogen, silicic acid, metals, and organic carbon. Furthermore, this ash leachate resulted in an increase of relative abundance of eukaryotic phytoplankton. Since the impacts of wildfire products on Macrocystis pyrifera remain understudied, this could be a valuable area for investigation. Additional factors to consider would include kelp recruitment rates using a temporal lag model and dissolved metal concentrations.\n\n\n\n\n\n\nData\nCitation\nLink\n\n\n\n\nSBC LTER: Ocean: Ocean Currents and Biogeochemistry: Nearshore water profiles (monthly CTD and chemistry), ongoing since 2000\nWashburn, L., M. Brzezinski, C. Carlson, and D. Siegel. 2024. SBC LTER: Ocean: Ocean Currents and Biogeochemistry: Nearshore water profiles (monthly CTD and chemistry), ongoing since 2000 ver 31. Environmental Data Initiative. https://doi.org/10.6073/pasta/cc75e947e0137e1594ebd8ce4b4a8880 (Accessed 2024-12-09).\nhttps://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-sbc.10.31\n\n\nSBC LTER: Reef: Annual time series of biomass for kelp forest species, ongoing since 2000\nReed, D. and R. Miller. 2024. SBC LTER: Reef: Annual time series of biomass for kelp forest species, ongoing since 2000 ver 17. Environmental Data Initiative. https://doi.org/10.6073/pasta/6587ad06e299e566e2092d1268dc206b (Accessed 2024-12-10).\nhttps://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-sbc.50.17"
  },
  {
    "objectID": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#background",
    "href": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#background",
    "title": "Ocean Chemistry and Santa Barbara Channel Macrocystis Pyrifera Populations",
    "section": "",
    "text": "Santa Barbara’s coastal waters host some of the most productive marine ecosystems on earth, Macrocystis pyrifera, or giant kelp forests. Kelp are a keystone species, and provide food, shelter and protection for all kinds of marine life, including commercially valuable fisheries. According to NOAA, factors influencing kelp forest growth include nutrients, light levels, temperatures, and ocean currents. Research by Smith et. al newly found that kelp use urea, in addition to ammonium, nitrate, dissolved organic nitrogen as nutrients for growth.\nIn this analysis, I would like to examine the relationship between ocean chemistry and kelp forest biomass, and develop a model for nutrient growth factors on biomass.\nThis exercise was produced as a part of the UCSB MEDS Program for EDS 222: Statistics for Environmental Data Science, taught by Dr. Max Czapanskiy."
  },
  {
    "objectID": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#dataset-descriptions",
    "href": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#dataset-descriptions",
    "title": "Ocean Chemistry and Santa Barbara Channel Macrocystis Pyrifera Populations",
    "section": "",
    "text": "1. SBC LTER: Reef: Annual time series of biomass for kelp forest species, ongoing since 2000\n\nThese data are annual estimates of biomass of approximately 225 taxa of reef algae, invertebrates and fish in permanent transects at 11 kelp forest sites in the Santa Barbara Channel (2-8 transects per site). Abundance is measured annually (as percent cover or density, by size) and converted to biomass (i.e., wet mass, dry mass, decalcified dry mass, ash free dry mass) using published taxon-specific algorithms. Data collection began in summer 2000 and continues annually in summer to provide information on community structure, population dynamics and species change.\n\n\n\n\nSBC LTER Reef Sites\n\n\n2. SBC LTER: Ocean: Ocean Currents and Biogeochemistry: Nearshore water profiles (monthly CTD and chemistry), ongoing since 2000\n\nThese data contain water chemistry measurements taken monthly at these reefs in the nearshore areas of the Santa Barbra Channel, CA, USA: Arroyo Quemado, Bullito, Naples, Arroyo Burro, Mohawk and Carpinteria. Measurements include standard CTD parameters, nutrients, pigments, particulate CN, total dissolved N and P, stable isotopes of C and N (not all parameters are measured at all stations). Sampling began in November 2000. Starting in February 2003, a SBE19-Plus with a rosette sampler was used. Some stations are sampled only occasionally.\n\n\n\n\nSBC LTER Ocean Bottle Sites\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(here)\nlibrary(readtext)\nlibrary(janitor)\n\ntheme_set(theme_bw())\nset.seed(42)\n\n\n\n\nCode\n# Read in kelp and ocean chemistry data\nspecies &lt;- read_csv(here::here(\n  \"posts/2024-12-12-ocean-chem-kelp/data/Annual_All_Species_Biomass_at_transect_20240823.csv\"), na = \"-99999\") %&gt;%\n  janitor::clean_names()\n\nocean_chem &lt;- read.table(here::here(\"posts/2024-12-12-ocean-chem-kelp/data/LTER_monthly_bottledata_20240821.txt\"), \n  header = TRUE, sep = \";\", na = c(\"BDL\", \"99999\")) %&gt;% # `BDL` = below detection level\n  janitor::clean_names()\n\n# Filter to Giant kelp (Macrocystis pyrifera)\nkelp &lt;- species %&gt;%\n  filter(scientific_name == \"Macrocystis pyrifera\")\n\n\nThe variables I plan to use for ocean chemistry are (in units of micromoles per liter):\n\nno2_no3_umol_l = concentration of the sum of nitrate and nitrite\npon_umol_l = concentration of particulate organic nitrogen\ntdn_umol_l= concentration of dissolved nitrogen\nammonia_umol_l= concentration of ammonium\nurea_umol_l= concentration of urea\n\nThe variables I plan to use for kelp biomass are:\n\nwm_gm2 = areal wet mass of individuals or colony in grams per square meter\ndensity = density taxon per squared meter in number per square meter\n\nNote: there are other measures of biomass in ocean_chem. However, they are just linear transformations of wet mass."
  },
  {
    "objectID": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#clean-data",
    "href": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#clean-data",
    "title": "Ocean Chemistry and Santa Barbara Channel Macrocystis Pyrifera Populations",
    "section": "",
    "text": "Code\n# Summarize kelp data to monthly averages\nmonthly_kelp_data &lt;- kelp %&gt;%\n  group_by(year, month, site) %&gt;%\n  summarise(across(where(is.numeric), mean, na.rm = TRUE)) %&gt;%\n  mutate(date = as.Date(paste(year, month, \"01\", sep=\"-\")))\n\n# Summarize ocean chem data to monthly averages\nmonthly_ocean_data &lt;- ocean_chem %&gt;%\n  mutate(date = as.Date(yyyy_mm_dd),\n         year = lubridate::year(yyyy_mm_dd),\n         month = lubridate::month(yyyy_mm_dd)) %&gt;%\n  mutate(site = case_when(\n    station %in% c(\"QI\", \"QM\", \"QO\", \"QR\") ~ \"AQUE\", # match site names at both datasets\n    station %in% c(\"CI\", \"CO\", \"CR\") ~ \"CARP\",\n    station %in% c(\"MI\", \"MK\") ~ \"MOHK\",\n    station %in% c(\"NI\", \"NO\", \"NR\") ~ \"NAPL\",\n    station %in% c(\"BI\", \"BO\", \"BR\") ~ \"BULL\",\n    station %in% c(\"AB\") ~ \"ABUR\"\n  )) %&gt;%\n  group_by(year, month, site) %&gt;%\n  summarise(\n    across(where(is.numeric), mean),\n    n = dplyr::n()) %&gt;%\n  mutate(date = as.Date(paste(year, month, \"01\", sep=\"-\")))\n\n# Plot monthly average weight data\nggplot(monthly_kelp_data, aes(date, wm_gm2)) +\n  geom_line(color = \"#6d8c23\") +\n  geom_point() +\n  facet_wrap(~site) +\n  scale_x_date(date_breaks = \"4 years\",\n               date_labels = \"%Y\") +\n  labs(title = \"Monthly Average Giant Kelp Biomass by Site\",\n       x = \"Date\",\n       y = \"Wet Mass (g/m²)\") +\n  theme(axis.text.x = element_text(size = 6), angle = 45, hjust = 1)\n\n\n\n\n\n\n\n\n\nCode\n# Check which sites have monthly ocean chemistry data\nggplot(monthly_ocean_data, aes(date, n)) +\n  geom_line(color = \"#6d8c23\") +\n  geom_point(size = 0.1) +\n  facet_wrap(~site) +\n  scale_x_date(date_breaks = \"4 years\",\n               date_labels = \"%Y\") +\n  scale_y_continuous(expand = expansion(c(0, 0))) +\n  labs(title = \"Number of Ocean Chemistry Measurements by Site\",\n       x = \"Date\",\n       y = \"Number of Measurements\") +\n  theme(axis.text.x = element_text(size = 6), angle = 45, hjust = 1)\n\n\n\n\n\n\n\n\n\nNote that there is a significant amount of missing data.\n\n\nCode\n# Join kelp and ocean chemistry datasets\njoined_data &lt;- left_join(\n  monthly_kelp_data, \n  monthly_ocean_data, \n  by = join_by(year, month, site, date)) %&gt;% \n  mutate(\n    site = as.factor(site),\n    pon_umol_l_log = log1p(pon_umol_l),\n    wm_gm2_log = log1p(wm_gm2))\n\n\nAfter grouping and summarizing the data, we are left with very few data points. There are NO instances that account for all of the ocean chemistry and kelp biomass variables initially identified for analysis.\nLooking at the joined data, the column with the most complete data from the original variables seems to be pon_umol_l."
  },
  {
    "objectID": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#visualize-data",
    "href": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#visualize-data",
    "title": "Ocean Chemistry and Santa Barbara Channel Macrocystis Pyrifera Populations",
    "section": "",
    "text": "Code\n# Plot wet weight as a function of time\nggplot(joined_data, aes(date, wm_gm2)) +\n  geom_line(color = \"#6d8c23\") +\n  geom_point(size = 0.1) +\n  facet_wrap(~site) +\n  scale_x_date(date_breaks = \"4 years\",\n               date_labels = \"%Y\") +\n  scale_y_continuous(expand = expansion(c(0, 0))) +\n  labs(title = \"Giant Kelp Wet Mass Over Time by Site\",\n       x = \"Date\", \n       y = \"Wet Mass (g/m²)\") +\n  theme(axis.text.x = element_text(size = 6), angle = 45, hjust = 1)\n\n\n\n\n\n\n\n\n\nCode\n# Plot particulate organic nitrogen concentration as a function of time\nggplot(joined_data, aes(date, pon_umol_l)) +\n  geom_line(color = \"#6d8c23\") +\n  geom_point(size = 0.1) +\n  facet_wrap(~site) +\n  scale_x_date(date_breaks = \"4 years\",\n               date_labels = \"%Y\") +\n  scale_y_continuous(expand = expansion(c(0, 0))) +\n  labs(title = \"Particulate Organic Nitrogen Concentration Over Time by Site\",\n       x = \"Date\",\n       y = \"PON Concentration (μmol/L)\") +\n  theme(axis.text.x = element_text(size = 6), angle = 45, hjust = 1)\n\n\n\n\n\n\n\n\n\nCode\n# Plot particulate organic nitrogen as a function of wet mass\nggplot(joined_data, aes(wm_gm2, pon_umol_l)) +\n  geom_point(size = 1,\n             color = \"#6d8c23\") +\n  facet_wrap(~site) +\n  scale_y_continuous(expand = expansion(c(0, 0))) +\n  labs(title = \"PON Concentration vs Kelp Biomass by Site\",\n       x = \"Wet Mass (g/m²)\",\n       y = \"PON Concentration (μmol/L)\")\n\n\n\n\n\n\n\n\n\nCode\n# Plot particulate organic nitrogen as a function of log wet mass\nggplot(joined_data, aes(wm_gm2_log, pon_umol_l)) +\n  geom_point(size = 1,\n             color = \"#6d8c23\") +\n  facet_wrap(~site) +\n  scale_y_continuous(expand = expansion(c(0, 0))) +\n  labs(title = \"PON Concentration vs Log Kelp Biomass by Site\",\n       x = \"Log Wet Mass (g/m²)\",\n       y = \"PON Concentration (μmol/L)\")"
  },
  {
    "objectID": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#run-models",
    "href": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#run-models",
    "title": "Ocean Chemistry and Santa Barbara Channel Macrocystis Pyrifera Populations",
    "section": "",
    "text": "Is there a relationship between biomass and particulate organic nitrogen (PON) concentration?\n\n\nCode\n# 1. Biomass and particulate organic nitrogen\nmodel_wm &lt;- lm(formula = wm_gm2 ~ pon_umol_l + site, \n               data = joined_data) \nmodel_wm %&gt;% \n  summary()\n\n\n\nCall:\nlm(formula = wm_gm2 ~ pon_umol_l + site, data = joined_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3648.9 -1378.2  -418.3  1079.4  5162.0 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1246.88     673.76   1.851  0.06743 .  \npon_umol_l    147.54      53.95   2.735  0.00749 ** \nsiteNAPL      143.32     660.54   0.217  0.82870    \nsiteABUR    -1252.58     688.31  -1.820  0.07204 .  \nsiteAQUE      704.76     666.46   1.057  0.29307    \nsiteMOHK     3186.67     695.94   4.579 1.46e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2020 on 92 degrees of freedom\n  (166 observations deleted due to missingness)\nMultiple R-squared:  0.3592,    Adjusted R-squared:  0.3243 \nF-statistic: 10.31 on 5 and 92 DF,  p-value: 7.175e-08\n\n\nCode\n# 2. Log biomass and particulate organic nitrogen\nmodel_wm_log &lt;- lm(formula = wm_gm2_log ~ pon_umol_l + site, \n                   data = joined_data) \nmodel_wm_log %&gt;% \n  summary()\n\n\n\nCall:\nlm(formula = wm_gm2_log ~ pon_umol_l + site, data = joined_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.7046 -0.6219  0.3389  0.8050  3.1095 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.57754    0.48030  13.695  &lt; 2e-16 ***\npon_umol_l   0.06801    0.03846   1.768  0.08032 .  \nsiteNAPL     0.16902    0.47088   0.359  0.72046    \nsiteABUR    -1.38850    0.49067  -2.830  0.00572 ** \nsiteAQUE     0.45671    0.47509   0.961  0.33892    \nsiteMOHK     1.49788    0.49611   3.019  0.00328 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.44 on 92 degrees of freedom\n  (166 observations deleted due to missingness)\nMultiple R-squared:  0.2987,    Adjusted R-squared:  0.2605 \nF-statistic: 7.836 on 5 and 92 DF,  p-value: 3.512e-06\n\n\nCode\n# 3. Density and particulate organic nitrogen\nmodel_wm_density &lt;- lm(formula = density ~ pon_umol_l + site, \n                       data = joined_data) \nmodel_wm_density %&gt;% \n  summary()\n\n\n\nCall:\nlm(formula = density ~ pon_umol_l + site, data = joined_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.7742 -2.6087 -0.6179  1.8569 10.1785 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   1.7383     1.2152   1.430  0.15598    \npon_umol_l    0.3174     0.0973   3.261  0.00156 ** \nsiteNAPL      0.6812     1.1914   0.572  0.56885    \nsiteABUR     -1.8348     1.2414  -1.478  0.14285    \nsiteAQUE      1.4354     1.2020   1.194  0.23551    \nsiteMOHK      7.8533     1.2552   6.256 1.23e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.644 on 92 degrees of freedom\n  (166 observations deleted due to missingness)\nMultiple R-squared:  0.4621,    Adjusted R-squared:  0.4328 \nF-statistic: 15.81 on 5 and 92 DF,  p-value: 3.266e-11\n\n\n1. Biomass Model model_wm\nThere is a significant positive relationship between PON and kelp biomass (p = 0.00749). For every one μmol/L increase in PON concentration, kelp wet mass increases by 147.54 grams/square meter when the reference site is BULL. Consistent with the “Monthly Average Giant Kelp Biomass by Site” plot, the MOHK site has significantly higher biomass than the other sites (coef = 3187.67, p = 1.46e-5). The model explains about 32.4% of the variation in biomass (not great).\n2. Log Biomass Model model_wm_log\nThere is a marginally significant positive relationship between PON and log-transformed kelp biomass (p = 0.080). For every one μmol/L increase in PON concentration, log kelp wet mass increases by 0.068 units when the reference site is BULL. The ABUR site shows significantly lower biomass (coef = -1.389, p = 0.006) while MOHK shows significantly higher biomass (coef = 1.498, p = 0.003) compared to other sites. The model explains about 26.1% of the variation in log biomass (poor fit).\n3. Biomass Density Model model_wm_density\nThere is a significant positive relationship between PON and kelp density (p = 0.002). For every one μmol/L increase in PON concentration, kelp density increases by 0.317 individuals per square meter when the reference site is BULL. Similar to the biomass models, the MOHK site shows significantly higher density than other sites (coef = 7.853, p &lt; 0.001). This model has the best fit of the three, explaining about 43.3% of the variation in density, but still is not great."
  },
  {
    "objectID": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#randomization-test",
    "href": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#randomization-test",
    "title": "Ocean Chemistry and Santa Barbara Channel Macrocystis Pyrifera Populations",
    "section": "",
    "text": "Hypotheses:\n\nH0: Particulate organic nitrogen has no effect on kelp biomass\nHA: Particulate organic nitrogen has an effect on kelp biomass\n\n\n\nCode\n# Get observed coefficient for pon_umol_l\nobserved_coef &lt;- coef(summary(model_wm))[\"pon_umol_l\", \"t value\"]\n\n# Create randomizations\nnull_dist &lt;- replicate(1000, {\n  rand_joined_data &lt;- joined_data %&gt;% \n    ungroup() %&gt;% \n    mutate(pon_umol_l = sample(pon_umol_l))\n  \n  rand_model &lt;- lm(wm_gm2 ~ pon_umol_l + site, data = rand_joined_data)\n  coef(summary(rand_model))[\"pon_umol_l\", \"t value\"]\n})\n\n# Calculate p-value (two-sided test)\np_value &lt;- mean(abs(null_dist) &gt;= abs(observed_coef))\n\n# Plot the null distribution\nnull_dist_df &lt;- data.frame(t_stat = null_dist)\nggplot(null_dist_df, aes(x = t_stat)) +\n  geom_histogram(binwidth = 0.2, \n                 fill = \"#6d8c23\", \n                 color = \"white\") +\n  geom_vline(xintercept = observed_coef, color = \"orchid\", linewidth = 1) +\n  labs(title = \"Null Distribution of PON Coefficient t-statistics\",\n       x = \"t-statistic\",\n       y = \"Count\")\n\n\n\n\n\n\n\n\n\nCode\ncat(\"Randomization test p-value:\", p_value, \"\\n\")\n\n\nRandomization test p-value: 0.003 \n\n\nCode\ncat(\"Observed t-statistic:\", observed_coef, \"\\n\")\n\n\nObserved t-statistic: 2.734869 \n\n\nThis randomization test shuffled the data n = 1000 times to determine what the point estimate (t-statistic) would be if it occurred by chance. 0nly 0.3% of the time would a value of t = 2.37 be produced as chance. At a threshold of alpha = 0.05, we can reject our null hypothesis and state that PON has a positive effect on kelp wet mass.\nThe observed t-statistic is 2.73, which means that the estimated coefficient is 2.73 standard errors away from zero. In the figure, the null distribution shows us what we would expect if there was no relationship between PON and biomass (measured by density). The purple line falls outside of the majority of the distribution, which tells us that there is a strong relationship between PON and density."
  },
  {
    "objectID": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#conclusion",
    "href": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#conclusion",
    "title": "Ocean Chemistry and Santa Barbara Channel Macrocystis Pyrifera Populations",
    "section": "",
    "text": "Due to incomplete data, I could not perform my intended analysis. The ocean chemistry and kelp data were inconsistently collected across sites and months, leaving very few usable data points after cleaning.\nThe model likely suffers from omitted variable bias. While prior research has established that temperature, currents, and light levels affect kelp growth, my model only included PON and site as variables, excluding other nutrients and physical variables.\nAutocorrelation may have affected the results because samples were taken at monthly intervals, and ecological conditions typically carry over from one month to the next. This violation of independence could lead to underestimated standard errors and overstated significance in the statistical results. However, techniques to reduce autocorrelation, such as a temporal lag model, were not feasible given the substantial missing data, which included gaps of several months in the joined dataset.\nOverall, the results of my models should not be considered reliable due to the significant data gaps. I had overestimated the completeness of the LTER data for this research question.\nFor future research, I would like to analyze Thomas Fire effects on kelp growth using a more complete ocean chemistry dataset. Researchers at UCSB discovered that wildfire ash from the 2017 Thomas Fire resulted in significant additions of dissolved nutrients, including inorganic and organic nitrogen, silicic acid, metals, and organic carbon. Furthermore, this ash leachate resulted in an increase of relative abundance of eukaryotic phytoplankton. Since the impacts of wildfire products on Macrocystis pyrifera remain understudied, this could be a valuable area for investigation. Additional factors to consider would include kelp recruitment rates using a temporal lag model and dissolved metal concentrations."
  },
  {
    "objectID": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#data-citations",
    "href": "posts/2024-12-12-ocean-chem-kelp/final-project-clean.html#data-citations",
    "title": "Ocean Chemistry and Santa Barbara Channel Macrocystis Pyrifera Populations",
    "section": "",
    "text": "Data\nCitation\nLink\n\n\n\n\nSBC LTER: Ocean: Ocean Currents and Biogeochemistry: Nearshore water profiles (monthly CTD and chemistry), ongoing since 2000\nWashburn, L., M. Brzezinski, C. Carlson, and D. Siegel. 2024. SBC LTER: Ocean: Ocean Currents and Biogeochemistry: Nearshore water profiles (monthly CTD and chemistry), ongoing since 2000 ver 31. Environmental Data Initiative. https://doi.org/10.6073/pasta/cc75e947e0137e1594ebd8ce4b4a8880 (Accessed 2024-12-09).\nhttps://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-sbc.10.31\n\n\nSBC LTER: Reef: Annual time series of biomass for kelp forest species, ongoing since 2000\nReed, D. and R. Miller. 2024. SBC LTER: Reef: Annual time series of biomass for kelp forest species, ongoing since 2000 ver 17. Environmental Data Initiative. https://doi.org/10.6073/pasta/6587ad06e299e566e2092d1268dc206b (Accessed 2024-12-10).\nhttps://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-sbc.50.17"
  },
  {
    "objectID": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html",
    "href": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html",
    "title": "Aquaculture Suitability Map",
    "section": "",
    "text": "As global demand for sustainable protein grows, marine aquaculture offers an alternative to land-based meat production. Gentry et al. found through mapping potential for marine aquaculture using multiple constraints, that global seafood demand could be met using less than 0.015% of global ocean area.\nThis exercise determines which Exclusive Economic Zones (EEZ) on the West Coast of the US are best suited to developing marine aquaculture to several species of oysters, and develops a function for visualizing suitability based on a single species—Pteria sterna, the Pacific winged oyster—in this case.\n\n\nshow code\n# Load libraries\nlibrary(terra)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(tmap)\nlibrary(testthat)\n\n\n\n\nshow code\n# Source external script that defines a custom function for aquaculture suitability\nsource(here::here(\"posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.R\"))\n\n\nThis function will also be provided below as part of hwk4.qmd.\n\n\n\n\n\nshow code\n# Read in Sea Surface Temperature, Bathymetry, and EEZ data\nfiles &lt;- list.files(here::here(\"posts/2024-12-24-aquaculture-suitability/data\"), pattern = \"average*\", full.names = TRUE)\nsst &lt;- terra::rast(files)\nnames(sst) &lt;- c(2008, 2009, 2010, 2011, 2012)\n\nif (nlyr(sst) == 0) {\n  stop(\"No layers found in SST data\")\n}\n\ndepth &lt;- terra::rast(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"depth.tif\")) %&gt;%\n  project(., y = crs(sst))\n\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n\nshow code\nwc_eez &lt;- st_read(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"wc_regions_clean.shp\"), quiet = TRUE) %&gt;%\n  st_transform(., crs = crs(sst))\n\n\n\n\nshow code\n# Check that the CRSs match for the datasets\ntestthat::test_that(\"Coordinate reference systems match\", {\n  expect_equal(crs(sst), crs(depth))\n  expect_equal(crs(depth), crs(wc_eez))\n})\n\n\nTest passed 🎉\n\n\n\n\nshow code\n# Import US state boundaries for plotting\nstates &lt;- st_read(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"states\", \"cb_2023_us_state_20m.shp\"), quiet = TRUE) %&gt;%\n  filter(NAME %in% c(\"California\", \"Oregon\", \"Washington\", \"Nevada\")) %&gt;%\n  st_transform(., crs = crs(sst)) %&gt;%\n  st_crop(., st_bbox(wc_eez))\n\n\n\n\n\n\n\nshow code\nsst_mean &lt;- sst %&gt;%\n  terra::mean() %&gt;%\n  - 273.15 # Convert from ºK to ºC\n\ndepth_cropped &lt;- crop(depth, sst_mean)\n\nif (res(depth_cropped)[1] != res(sst_mean)[1]) {\n  warning(sprintf(\"Resolution mismatch\", \n                  res(depth_cropped)[1], res(sst_mean)[1]))\n}\n\ndepth_resample &lt;- resample(depth_cropped, sst_mean, method = \"near\")\n\next(depth_resample) == ext(sst_mean)\n\n\n[1] TRUE\n\n\nshow code\n# Check that the depth and SST rasters match in resolution, extent, and position\ndepth_sst_stack &lt;- c(depth_resample, sst_mean)\n\n\n\n\n\nResearch has shown that oysters need the following conditions for optimal growth:\n\nsea surface temperature: 11-30°C\ndepth: 0-70 meters below sea level\n\n\n\nshow code\n# Define reclassification matrices for depth and SST\nrcl_depth &lt;- matrix(c(-Inf, -70, 0,\n                      -70, 0, 1,\n                      0, Inf, 0),\n                    ncol = 3, byrow = TRUE)\nrcl_sst &lt;- matrix(c(-Inf, 11, 0,\n                    11, 30, 1,\n                    30, Inf, 0),\n                  ncol = 3, byrow = TRUE)\n\n# Apply the matrices to the depth and SST rasters, making all cells 0 or 1\ndepth_rcl &lt;- terra::classify(depth_resample, rcl = rcl_depth)\nsst_rcl &lt;- terra::classify(sst_mean, rcl = rcl_sst)\n\n# Find locations that satisfy both SST and depth conditions\nsuitablility &lt;- function(depth_rcl, sst_rcl) {\n  depth_rcl*sst_rcl\n}\nsuitable &lt;- lapp(c(depth_rcl, sst_rcl), fun = suitablility)\n\n\n\n\n\n\n\nshow code\n# Set unsuitable locations to NAs\nsuitable[suitable == 0] &lt;- NA\n\n# Find the total suitable area within each EEZ\neez_area &lt;- terra::cellSize(suitable, mask = T, unit = \"km\")\nsuitable_eez_area &lt;- exactextractr::exact_extract(\n  eez_area, wc_eez, \n  fun = \"sum\", \n  append_cols=c(\"rgn\", \"area_km2\"), \n  progress = FALSE)\n\n# Join to original data to obtain geometries for visualization\nsuitable_eez_join &lt;- left_join(wc_eez, suitable_eez_area)\n\ntm_shape(suitable_eez_join) +\n  tm_fill(col = \"sum\",\n          style = \"pretty\",\n          palette = \"Blues\",\n          title = \"Suitable Area (km\\u00b2)\") +\n  tm_text(text = \"rgn\",\n          size = 0.7) +\n  tm_shape(states) +\n  tm_polygons(col = \"#e3d3b8\",\n              border.col = \"#402618\") +\n  tm_shape(wc_eez) +\n  tm_borders(col = \"#402618\") +\n  tm_layout(main.title = paste(\"Suitable Area for Oyster Fisheries \\nin West Coast EEZ\"),\n            bg.color = \"#e8ebea\",\n            legend.bg.color = \"#e3d3b8\",\n            legend.position = c(0.61, 0.85)) +\n  tm_scale_bar(position = c(\"left\", \"bottom\")) +\n  tm_compass(position = c(\"right\", \"bottom\"),\n             size = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nUsing the provided depth, sea surface temperature, West Coast Exclusive Economic Zones, and states data, we can conduct a suitability analysis and produce a suitability map for any species of interest for marine aquaculture given their sea surface temperature range, depth range and species name.\n\n\nshow code\nsuitable_aquaculture &lt;- function(min_temp, max_temp, min_depth, max_depth, species) {\n  # Read and prepare data\n  files &lt;- list.files(here::here(\"posts/2024-12-24-aquaculture-suitability/data\"), pattern = \"average*\", full.names = TRUE)\n  sst &lt;- terra::rast(files)\n  names(sst) &lt;- c(2008, 2009, 2010, 2011, 2012)\n  \n  # Import bathymetry data\n  depth &lt;- terra::rast(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"depth.tif\"))\n  \n  # Import EEZ and state boundaries\n  wc_eez &lt;- st_read(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"wc_regions_clean.shp\"), quiet = TRUE) %&gt;%\n    st_transform(., crs = crs(sst))\n  \n  states &lt;- st_read(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"states\", \"cb_2023_us_state_20m.shp\"), quiet = TRUE) %&gt;%\n    filter(NAME %in% c(\"California\", \"Oregon\", \"Washington\", \"Nevada\")) %&gt;%\n    st_transform(., crs = crs(sst)) %&gt;%\n    st_crop(., st_bbox(wc_eez))\n  \n  # Process SST data\n  sst_mean &lt;- sst %&gt;%\n    terra::mean() %&gt;%\n    - 273.15  # Convert from Kelvin to Celsius\n  \n  # Process depth data\n  depth &lt;- project(depth, y = crs(sst))\n  depth_cropped &lt;- crop(depth, sst_mean)\n  depth_resample &lt;- resample(depth_cropped, sst_mean, method = \"near\")\n  \n  # Create reclassification matrices\n  rcl_depth &lt;- matrix(c(-Inf, -max_depth, 0,\n                        -max_depth, min_depth, 1,\n                        min_depth, Inf, 0),\n                      ncol = 3, byrow = TRUE)\n  rcl_sst &lt;- matrix(c(-Inf, min_temp, 0,\n                      min_temp, max_temp, 1,\n                      max_temp, Inf, 0),\n                    ncol = 3, byrow = TRUE)\n  \n  # Apply matrices to depth and SST rasters\n  depth_rcl &lt;- terra::classify(depth_resample, rcl = rcl_depth)\n  sst_rcl &lt;- terra::classify(sst_mean, rcl = rcl_sst)\n  \n  # Find locations that satisfy both SST and depth conditions\n  suitablility &lt;- function(depth_rcl, sst_rcl) {\n    depth_rcl*sst_rcl\n  }\n  suitable &lt;- lapp(c(depth_rcl, sst_rcl), fun = suitablility)\n  \n  # Set unsuitable locations to NA\n  suitable[suitable == 0] &lt;- NA\n  \n  # Find the total suitable area within each EEZ\n  eez_area &lt;- terra::cellSize(suitable, mask = T, unit = \"km\")\n  suitable_eez_area &lt;- exactextractr::exact_extract(eez_area, wc_eez, \n                                                    fun = \"sum\", \n                                                    append_cols=c(\"rgn\", \"area_km2\"), \n                                                    progress = FALSE)\n  \n  # Join to original data to obtain geometries for visualization\n  suitable_eez_join &lt;- left_join(wc_eez, suitable_eez_area, by = join_by(rgn, area_km2))\n  \n  # Visualize suitable area\n  tm_shape(suitable_eez_join) +\n    tm_fill(col = \"sum\",\n            style = \"pretty\",\n            palette = \"Blues\",\n            title = \"Suitable Area (km\\u00b2)\") +\n    tm_text(text = \"rgn\",\n            size = 0.7) +\n    tm_shape(states) +\n    tm_polygons(col = \"#e3d3b8\",\n                border.col = \"#402618\") +\n    tm_shape(wc_eez) +\n    tm_borders(col = \"#402618\") +\n    tm_layout(main.title = paste(\"Suitable Area for\", \n                                 species,\n                                 \"\\nFisheries in West Coast EEZ\"),\n              bg.color = \"#e8ebea\",\n              legend.bg.color = \"#e3d3b8\",\n              legend.position = c(0.61, 0.85)) +\n    tm_scale_bar(position = c(\"left\", \"bottom\")) +\n    tm_compass(position = c(\"right\", \"bottom\"),\n               size = 2)\n}\n\n\n\n\n\nPteria sterna or the Pacific wing-oyster is an eastern Pacific oyster of commercial value.\nConditions for optimal growth:\n\nsea surface temperature: 10-30°C\ndepth: 3-26 meters below sea level\n\n\n\nshow code\nsuitable_aquaculture(10, 30, 3, 26, \"Pteria sterna\")\n\n\n\n|---------|---------|---------|---------|\n========================================="
  },
  {
    "objectID": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#background",
    "href": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#background",
    "title": "Aquaculture Suitability Map",
    "section": "",
    "text": "As global demand for sustainable protein grows, marine aquaculture offers an alternative to land-based meat production. Gentry et al. found through mapping potential for marine aquaculture using multiple constraints, that global seafood demand could be met using less than 0.015% of global ocean area.\nThis exercise determines which Exclusive Economic Zones (EEZ) on the West Coast of the US are best suited to developing marine aquaculture to several species of oysters, and develops a function for visualizing suitability based on a single species—Pteria sterna, the Pacific winged oyster—in this case.\n\n\nshow code\n# Load libraries\nlibrary(terra)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(tmap)\nlibrary(testthat)\n\n\n\n\nshow code\n# Source external script that defines a custom function for aquaculture suitability\nsource(here::here(\"posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.R\"))\n\n\nThis function will also be provided below as part of hwk4.qmd."
  },
  {
    "objectID": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#prepare-data",
    "href": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#prepare-data",
    "title": "Aquaculture Suitability Map",
    "section": "",
    "text": "show code\n# Read in Sea Surface Temperature, Bathymetry, and EEZ data\nfiles &lt;- list.files(here::here(\"posts/2024-12-24-aquaculture-suitability/data\"), pattern = \"average*\", full.names = TRUE)\nsst &lt;- terra::rast(files)\nnames(sst) &lt;- c(2008, 2009, 2010, 2011, 2012)\n\nif (nlyr(sst) == 0) {\n  stop(\"No layers found in SST data\")\n}\n\ndepth &lt;- terra::rast(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"depth.tif\")) %&gt;%\n  project(., y = crs(sst))\n\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n\nshow code\nwc_eez &lt;- st_read(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"wc_regions_clean.shp\"), quiet = TRUE) %&gt;%\n  st_transform(., crs = crs(sst))\n\n\n\n\nshow code\n# Check that the CRSs match for the datasets\ntestthat::test_that(\"Coordinate reference systems match\", {\n  expect_equal(crs(sst), crs(depth))\n  expect_equal(crs(depth), crs(wc_eez))\n})\n\n\nTest passed 🎉\n\n\n\n\nshow code\n# Import US state boundaries for plotting\nstates &lt;- st_read(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"states\", \"cb_2023_us_state_20m.shp\"), quiet = TRUE) %&gt;%\n  filter(NAME %in% c(\"California\", \"Oregon\", \"Washington\", \"Nevada\")) %&gt;%\n  st_transform(., crs = crs(sst)) %&gt;%\n  st_crop(., st_bbox(wc_eez))"
  },
  {
    "objectID": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#process-data",
    "href": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#process-data",
    "title": "Aquaculture Suitability Map",
    "section": "",
    "text": "show code\nsst_mean &lt;- sst %&gt;%\n  terra::mean() %&gt;%\n  - 273.15 # Convert from ºK to ºC\n\ndepth_cropped &lt;- crop(depth, sst_mean)\n\nif (res(depth_cropped)[1] != res(sst_mean)[1]) {\n  warning(sprintf(\"Resolution mismatch\", \n                  res(depth_cropped)[1], res(sst_mean)[1]))\n}\n\ndepth_resample &lt;- resample(depth_cropped, sst_mean, method = \"near\")\n\next(depth_resample) == ext(sst_mean)\n\n\n[1] TRUE\n\n\nshow code\n# Check that the depth and SST rasters match in resolution, extent, and position\ndepth_sst_stack &lt;- c(depth_resample, sst_mean)"
  },
  {
    "objectID": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#find-suitable-locations-for-marine-aquaculture",
    "href": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#find-suitable-locations-for-marine-aquaculture",
    "title": "Aquaculture Suitability Map",
    "section": "",
    "text": "Research has shown that oysters need the following conditions for optimal growth:\n\nsea surface temperature: 11-30°C\ndepth: 0-70 meters below sea level\n\n\n\nshow code\n# Define reclassification matrices for depth and SST\nrcl_depth &lt;- matrix(c(-Inf, -70, 0,\n                      -70, 0, 1,\n                      0, Inf, 0),\n                    ncol = 3, byrow = TRUE)\nrcl_sst &lt;- matrix(c(-Inf, 11, 0,\n                    11, 30, 1,\n                    30, Inf, 0),\n                  ncol = 3, byrow = TRUE)\n\n# Apply the matrices to the depth and SST rasters, making all cells 0 or 1\ndepth_rcl &lt;- terra::classify(depth_resample, rcl = rcl_depth)\nsst_rcl &lt;- terra::classify(sst_mean, rcl = rcl_sst)\n\n# Find locations that satisfy both SST and depth conditions\nsuitablility &lt;- function(depth_rcl, sst_rcl) {\n  depth_rcl*sst_rcl\n}\nsuitable &lt;- lapp(c(depth_rcl, sst_rcl), fun = suitablility)"
  },
  {
    "objectID": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#determine-the-most-suitable-eez",
    "href": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#determine-the-most-suitable-eez",
    "title": "Aquaculture Suitability Map",
    "section": "",
    "text": "show code\n# Set unsuitable locations to NAs\nsuitable[suitable == 0] &lt;- NA\n\n# Find the total suitable area within each EEZ\neez_area &lt;- terra::cellSize(suitable, mask = T, unit = \"km\")\nsuitable_eez_area &lt;- exactextractr::exact_extract(\n  eez_area, wc_eez, \n  fun = \"sum\", \n  append_cols=c(\"rgn\", \"area_km2\"), \n  progress = FALSE)\n\n# Join to original data to obtain geometries for visualization\nsuitable_eez_join &lt;- left_join(wc_eez, suitable_eez_area)\n\ntm_shape(suitable_eez_join) +\n  tm_fill(col = \"sum\",\n          style = \"pretty\",\n          palette = \"Blues\",\n          title = \"Suitable Area (km\\u00b2)\") +\n  tm_text(text = \"rgn\",\n          size = 0.7) +\n  tm_shape(states) +\n  tm_polygons(col = \"#e3d3b8\",\n              border.col = \"#402618\") +\n  tm_shape(wc_eez) +\n  tm_borders(col = \"#402618\") +\n  tm_layout(main.title = paste(\"Suitable Area for Oyster Fisheries \\nin West Coast EEZ\"),\n            bg.color = \"#e8ebea\",\n            legend.bg.color = \"#e3d3b8\",\n            legend.position = c(0.61, 0.85)) +\n  tm_scale_bar(position = c(\"left\", \"bottom\")) +\n  tm_compass(position = c(\"right\", \"bottom\"),\n             size = 2)"
  },
  {
    "objectID": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#single-species-analysis-function",
    "href": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#single-species-analysis-function",
    "title": "Aquaculture Suitability Map",
    "section": "",
    "text": "Using the provided depth, sea surface temperature, West Coast Exclusive Economic Zones, and states data, we can conduct a suitability analysis and produce a suitability map for any species of interest for marine aquaculture given their sea surface temperature range, depth range and species name.\n\n\nshow code\nsuitable_aquaculture &lt;- function(min_temp, max_temp, min_depth, max_depth, species) {\n  # Read and prepare data\n  files &lt;- list.files(here::here(\"posts/2024-12-24-aquaculture-suitability/data\"), pattern = \"average*\", full.names = TRUE)\n  sst &lt;- terra::rast(files)\n  names(sst) &lt;- c(2008, 2009, 2010, 2011, 2012)\n  \n  # Import bathymetry data\n  depth &lt;- terra::rast(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"depth.tif\"))\n  \n  # Import EEZ and state boundaries\n  wc_eez &lt;- st_read(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"wc_regions_clean.shp\"), quiet = TRUE) %&gt;%\n    st_transform(., crs = crs(sst))\n  \n  states &lt;- st_read(here::here(\"posts/2024-12-24-aquaculture-suitability/data\", \"states\", \"cb_2023_us_state_20m.shp\"), quiet = TRUE) %&gt;%\n    filter(NAME %in% c(\"California\", \"Oregon\", \"Washington\", \"Nevada\")) %&gt;%\n    st_transform(., crs = crs(sst)) %&gt;%\n    st_crop(., st_bbox(wc_eez))\n  \n  # Process SST data\n  sst_mean &lt;- sst %&gt;%\n    terra::mean() %&gt;%\n    - 273.15  # Convert from Kelvin to Celsius\n  \n  # Process depth data\n  depth &lt;- project(depth, y = crs(sst))\n  depth_cropped &lt;- crop(depth, sst_mean)\n  depth_resample &lt;- resample(depth_cropped, sst_mean, method = \"near\")\n  \n  # Create reclassification matrices\n  rcl_depth &lt;- matrix(c(-Inf, -max_depth, 0,\n                        -max_depth, min_depth, 1,\n                        min_depth, Inf, 0),\n                      ncol = 3, byrow = TRUE)\n  rcl_sst &lt;- matrix(c(-Inf, min_temp, 0,\n                      min_temp, max_temp, 1,\n                      max_temp, Inf, 0),\n                    ncol = 3, byrow = TRUE)\n  \n  # Apply matrices to depth and SST rasters\n  depth_rcl &lt;- terra::classify(depth_resample, rcl = rcl_depth)\n  sst_rcl &lt;- terra::classify(sst_mean, rcl = rcl_sst)\n  \n  # Find locations that satisfy both SST and depth conditions\n  suitablility &lt;- function(depth_rcl, sst_rcl) {\n    depth_rcl*sst_rcl\n  }\n  suitable &lt;- lapp(c(depth_rcl, sst_rcl), fun = suitablility)\n  \n  # Set unsuitable locations to NA\n  suitable[suitable == 0] &lt;- NA\n  \n  # Find the total suitable area within each EEZ\n  eez_area &lt;- terra::cellSize(suitable, mask = T, unit = \"km\")\n  suitable_eez_area &lt;- exactextractr::exact_extract(eez_area, wc_eez, \n                                                    fun = \"sum\", \n                                                    append_cols=c(\"rgn\", \"area_km2\"), \n                                                    progress = FALSE)\n  \n  # Join to original data to obtain geometries for visualization\n  suitable_eez_join &lt;- left_join(wc_eez, suitable_eez_area, by = join_by(rgn, area_km2))\n  \n  # Visualize suitable area\n  tm_shape(suitable_eez_join) +\n    tm_fill(col = \"sum\",\n            style = \"pretty\",\n            palette = \"Blues\",\n            title = \"Suitable Area (km\\u00b2)\") +\n    tm_text(text = \"rgn\",\n            size = 0.7) +\n    tm_shape(states) +\n    tm_polygons(col = \"#e3d3b8\",\n                border.col = \"#402618\") +\n    tm_shape(wc_eez) +\n    tm_borders(col = \"#402618\") +\n    tm_layout(main.title = paste(\"Suitable Area for\", \n                                 species,\n                                 \"\\nFisheries in West Coast EEZ\"),\n              bg.color = \"#e8ebea\",\n              legend.bg.color = \"#e3d3b8\",\n              legend.position = c(0.61, 0.85)) +\n    tm_scale_bar(position = c(\"left\", \"bottom\")) +\n    tm_compass(position = c(\"right\", \"bottom\"),\n               size = 2)\n}"
  },
  {
    "objectID": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#test-function-for-single-oyster-species",
    "href": "posts/2024-12-24-aquaculture-suitability/suitable-aquaculture.html#test-function-for-single-oyster-species",
    "title": "Aquaculture Suitability Map",
    "section": "",
    "text": "Pteria sterna or the Pacific wing-oyster is an eastern Pacific oyster of commercial value.\nConditions for optimal growth:\n\nsea surface temperature: 10-30°C\ndepth: 3-26 meters below sea level\n\n\n\nshow code\nsuitable_aquaculture(10, 30, 3, 26, \"Pteria sterna\")\n\n\n\n|---------|---------|---------|---------|\n========================================="
  },
  {
    "objectID": "deletelater/practice.html",
    "href": "deletelater/practice.html",
    "title": "Here is my level one header",
    "section": "",
    "text": "Here is my level one header\nHere is my first paragraph\nHere is my second paragraph, where you can read more about MEDS.\nThis is very important text!"
  },
  {
    "objectID": "portrait-photography.html#portraits",
    "href": "portrait-photography.html#portraits",
    "title": "Portrait Photography",
    "section": "Portraits",
    "text": "Portraits"
  },
  {
    "objectID": "portrait-photography.html#graduates",
    "href": "portrait-photography.html#graduates",
    "title": "Portrait Photography",
    "section": "Graduates",
    "text": "Graduates"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Final Blog Post\n\n\n\n\n\nSanta Barbara County voter data visualization\n\n\n\n\n\nMar 14, 2025\n\n\nLeilanie Rubinstein\n\n\n\n\n\n\n\n\n\n\n\n\nAquaculture Suitability Map\n\n\n\n\n\n\nR\n\n\nMarine\n\n\nGeospatial Analysis\n\n\n\nDetermining and visualizing which West Coast EEZs are best suited to developing species-specific marine aquaculture\n\n\n\n\n\nMar 14, 2025\n\n\nLeilanie Rubinstein\n\n\n\n\n\n\n\n\n\n\n\n\nOcean Chemistry and Santa Barbara Channel Macrocystis Pyrifera Populations\n\n\n\n\n\n\nR\n\n\nMarine\n\n\nStatistical Analysis\n\n\n\nInvestigating whether ocean chemistry has an impact on kelp forest biomass in the Santa Barbara Channel\n\n\n\n\n\nDec 24, 2024\n\n\nLeilanie Rubinstein\n\n\n\n\n\n\n\n\n\n\n\n\nThomas Fire: Perimeter Visualization & Land Cover Statistics\n\n\n\n\n\n\nPython\n\n\nMEDS\n\n\n\nTrue and false color visualization using Landsat data\n\n\n\n\n\nDec 13, 2024\n\n\nLeilanie Rubinstein\n\n\n\n\n\n\nNo matching items"
  }
]